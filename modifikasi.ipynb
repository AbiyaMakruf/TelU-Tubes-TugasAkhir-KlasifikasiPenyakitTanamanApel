{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c093da6e-7838-492d-8d0d-46fbfe19ed4c",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7218ac47-533c-4481-82ba-8f706a472510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.14.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /usr/local/lib/python3.11/dist-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4464ee44-bfa4-43e7-80a1-5d4120c4b33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.14.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /usr/local/lib/python3.11/dist-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee770f1-e1f6-4a33-8049-68306e4ab93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 14:38:23.852267: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-18 14:38:23.852308: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-18 14:38:23.852349: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-18 14:38:23.860499: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'ml_dtypes' has no attribute 'float8_e4m3b11'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: module 'ml_dtypes' has no attribute 'float8_e4m3b11'"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unable to convert function return value to a Python type! The signature was\n\t() -> handle",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py:42\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# from tensorflow.python import keras\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# from tensorflow.python.layers import layers\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saved_model\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Sub-package for performing i/o directly instead of via ops in a graph.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/saved_model.py:20\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Convenience functions to save a model.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m builder\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loader\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/builder.py:23\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"SavedModel builder.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mBuilds a SavedModel that can be saved to storage, is language neutral, and\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03menables systems to produce, consume, or transform TensorFlow Models.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder_impl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _SavedModelBuilder\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder_impl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SavedModelBuilder\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# pylint: enable=unused-import\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/builder_impl.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saved_model_pb2\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saver_pb2\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/dtypes.py:39\u001b[0m\n\u001b[1;32m     37\u001b[0m _np_bfloat16 \u001b[38;5;241m=\u001b[39m pywrap_ml_dtypes\u001b[38;5;241m.\u001b[39mbfloat16()\n\u001b[1;32m     38\u001b[0m _np_float8_e4m3fn \u001b[38;5;241m=\u001b[39m pywrap_ml_dtypes\u001b[38;5;241m.\u001b[39mfloat8_e4m3fn()\n\u001b[0;32m---> 39\u001b[0m _np_float8_e5m2 \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_ml_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat8_e5m2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDTypeMeta\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m(_dtypes\u001b[38;5;241m.\u001b[39mDType), abc\u001b[38;5;241m.\u001b[39mABCMeta):\n\u001b[1;32m     43\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unable to convert function return value to a Python type! The signature was\n\t() -> handle"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dropout, Dense, Input, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e92fb5-7cd5-49d3-9bb6-83a2f1ad4e30",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Cek apakah ada GPU yang tersedia\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m gpus \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gpus:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorFlow mendeteksi \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(gpus)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GPU:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Cek apakah ada GPU yang tersedia\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(f\"TensorFlow mendeteksi {len(gpus)} GPU:\")\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "else:\n",
    "    print(\"TensorFlow tidak mendeteksi GPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd26c7f-2d68-4ab3-bdb9-4f5485aaee0d",
   "metadata": {},
   "source": [
    "# EfficientNet Original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c89e40-f138-4731-bee5-6653158eda8f",
   "metadata": {},
   "source": [
    "## Source code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c8bb9ad-0686-4d80-a442-5e95cde1d25d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.src.api_export'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m imagenet_utils\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.src.api_export'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import math\n",
    "\n",
    "from keras.src import backend\n",
    "from keras.src import layers\n",
    "from keras.src.api_export import keras_export\n",
    "from keras.src.applications import imagenet_utils\n",
    "from keras.src.models import Functional\n",
    "from keras.src.ops import operation_utils\n",
    "from keras.src.utils import file_utils\n",
    "\n",
    "BASE_WEIGHTS_PATH = \"https://storage.googleapis.com/keras-applications/\"\n",
    "\n",
    "WEIGHTS_HASHES = {\n",
    "    \"b0\": (\n",
    "        \"902e53a9f72be733fc0bcb005b3ebbac\",\n",
    "        \"50bc09e76180e00e4465e1a485ddc09d\",\n",
    "    ),\n",
    "    \"b1\": (\n",
    "        \"1d254153d4ab51201f1646940f018540\",\n",
    "        \"74c4e6b3e1f6a1eea24c589628592432\",\n",
    "    ),\n",
    "    \"b2\": (\n",
    "        \"b15cce36ff4dcbd00b6dd88e7857a6ad\",\n",
    "        \"111f8e2ac8aa800a7a99e3239f7bfb39\",\n",
    "    ),\n",
    "    \"b3\": (\n",
    "        \"ffd1fdc53d0ce67064dc6a9c7960ede0\",\n",
    "        \"af6d107764bb5b1abb91932881670226\",\n",
    "    ),\n",
    "    \"b4\": (\n",
    "        \"18c95ad55216b8f92d7e70b3a046e2fc\",\n",
    "        \"ebc24e6d6c33eaebbd558eafbeedf1ba\",\n",
    "    ),\n",
    "    \"b5\": (\n",
    "        \"ace28f2a6363774853a83a0b21b9421a\",\n",
    "        \"38879255a25d3c92d5e44e04ae6cec6f\",\n",
    "    ),\n",
    "    \"b6\": (\n",
    "        \"165f6e37dce68623721b423839de8be5\",\n",
    "        \"9ecce42647a20130c1f39a5d4cb75743\",\n",
    "    ),\n",
    "    \"b7\": (\n",
    "        \"8c03f828fec3ef71311cd463b6759d99\",\n",
    "        \"cbcfe4450ddf6f3ad90b1b398090fe4a\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "DEFAULT_BLOCKS_ARGS = [\n",
    "    {\n",
    "        \"kernel_size\": 3,\n",
    "        \"repeats\": 1,\n",
    "        \"filters_in\": 32,\n",
    "        \"filters_out\": 16,\n",
    "        \"expand_ratio\": 1,\n",
    "        \"id_skip\": True,\n",
    "        \"strides\": 1,\n",
    "        \"se_ratio\": 0.25,\n",
    "    },\n",
    "    {\n",
    "        \"kernel_size\": 3,\n",
    "        \"repeats\": 2,\n",
    "        \"filters_in\": 16,\n",
    "        \"filters_out\": 24,\n",
    "        \"expand_ratio\": 6,\n",
    "        \"id_skip\": True,\n",
    "        \"strides\": 2,\n",
    "        \"se_ratio\": 0.25,\n",
    "    },\n",
    "    {\n",
    "        \"kernel_size\": 5,\n",
    "        \"repeats\": 2,\n",
    "        \"filters_in\": 24,\n",
    "        \"filters_out\": 40,\n",
    "        \"expand_ratio\": 6,\n",
    "        \"id_skip\": True,\n",
    "        \"strides\": 2,\n",
    "        \"se_ratio\": 0.25,\n",
    "    },\n",
    "    {\n",
    "        \"kernel_size\": 3,\n",
    "        \"repeats\": 3,\n",
    "        \"filters_in\": 40,\n",
    "        \"filters_out\": 80,\n",
    "        \"expand_ratio\": 6,\n",
    "        \"id_skip\": True,\n",
    "        \"strides\": 2,\n",
    "        \"se_ratio\": 0.25,\n",
    "    },\n",
    "    {\n",
    "        \"kernel_size\": 5,\n",
    "        \"repeats\": 3,\n",
    "        \"filters_in\": 80,\n",
    "        \"filters_out\": 112,\n",
    "        \"expand_ratio\": 6,\n",
    "        \"id_skip\": True,\n",
    "        \"strides\": 1,\n",
    "        \"se_ratio\": 0.25,\n",
    "    },\n",
    "    {\n",
    "        \"kernel_size\": 5,\n",
    "        \"repeats\": 4,\n",
    "        \"filters_in\": 112,\n",
    "        \"filters_out\": 192,\n",
    "        \"expand_ratio\": 6,\n",
    "        \"id_skip\": True,\n",
    "        \"strides\": 2,\n",
    "        \"se_ratio\": 0.25,\n",
    "    },\n",
    "    {\n",
    "        \"kernel_size\": 3,\n",
    "        \"repeats\": 1,\n",
    "        \"filters_in\": 192,\n",
    "        \"filters_out\": 320,\n",
    "        \"expand_ratio\": 6,\n",
    "        \"id_skip\": True,\n",
    "        \"strides\": 1,\n",
    "        \"se_ratio\": 0.25,\n",
    "    },\n",
    "]\n",
    "\n",
    "CONV_KERNEL_INITIALIZER = {\n",
    "    \"class_name\": \"VarianceScaling\",\n",
    "    \"config\": {\n",
    "        \"scale\": 2.0,\n",
    "        \"mode\": \"fan_out\",\n",
    "        \"distribution\": \"truncated_normal\",\n",
    "    },\n",
    "}\n",
    "\n",
    "DENSE_KERNEL_INITIALIZER = {\n",
    "    \"class_name\": \"VarianceScaling\",\n",
    "    \"config\": {\n",
    "        \"scale\": 1.0 / 3.0,\n",
    "        \"mode\": \"fan_out\",\n",
    "        \"distribution\": \"uniform\",\n",
    "    },\n",
    "}\n",
    "\n",
    "BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n",
    "\n",
    "Reference:\n",
    "- [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](\n",
    "    https://arxiv.org/abs/1905.11946) (ICML 2019)\n",
    "\n",
    "This function returns a Keras image classification model,\n",
    "optionally loaded with weights pre-trained on ImageNet.\n",
    "\n",
    "For image classification use cases, see\n",
    "[this page for detailed examples](\n",
    "https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n",
    "\n",
    "For transfer learning use cases, make sure to read the\n",
    "[guide to transfer learning & fine-tuning](\n",
    "https://keras.io/guides/transfer_learning/).\n",
    "\n",
    "Note: each Keras Application expects a specific kind of input preprocessing.\n",
    "For EfficientNet, input preprocessing is included as part of the model\n",
    "(as a `Rescaling` layer), and thus\n",
    "`keras.applications.efficientnet.preprocess_input` is actually a\n",
    "pass-through function. EfficientNet models expect their inputs to be float\n",
    "tensors of pixels with values in the `[0-255]` range.\n",
    "\n",
    "Args:\n",
    "    include_top: Whether to include the fully-connected\n",
    "        layer at the top of the network. Defaults to `True`.\n",
    "    weights: One of `None` (random initialization),\n",
    "        `\"imagenet\"` (pre-training on ImageNet),\n",
    "        or the path to the weights file to be loaded.\n",
    "        Defaults to `\"imagenet\"`.\n",
    "    input_tensor: Optional Keras tensor\n",
    "        (i.e. output of `layers.Input()`)\n",
    "        to use as image input for the model.\n",
    "    input_shape: Optional shape tuple, only to be specified\n",
    "        if `include_top` is False.\n",
    "        It should have exactly 3 inputs channels.\n",
    "    pooling: Optional pooling mode for feature extraction\n",
    "        when `include_top` is `False`. Defaults to `None`.\n",
    "        - `None` means that the output of the model will be\n",
    "            the 4D tensor output of the\n",
    "            last convolutional layer.\n",
    "        - `avg` means that global average pooling\n",
    "            will be applied to the output of the\n",
    "            last convolutional layer, and thus\n",
    "            the output of the model will be a 2D tensor.\n",
    "        - `max` means that global max pooling will\n",
    "            be applied.\n",
    "    classes: Optional number of classes to classify images\n",
    "        into, only to be specified if `include_top` is True, and\n",
    "        if no `weights` argument is specified. 1000 is how many\n",
    "        ImageNet classes there are. Defaults to `1000`.\n",
    "    classifier_activation: A `str` or callable. The activation function to use\n",
    "        on the \"top\" layer. Ignored unless `include_top=True`. Set\n",
    "        `classifier_activation=None` to return the logits of the \"top\" layer.\n",
    "        Defaults to `'softmax'`.\n",
    "        When loading pretrained weights, `classifier_activation` can only\n",
    "        be `None` or `\"softmax\"`.\n",
    "\n",
    "Returns:\n",
    "    A model instance.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "IMAGENET_STDDEV_RGB = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "def EfficientNet(\n",
    "    width_coefficient,\n",
    "    depth_coefficient,\n",
    "    default_size,\n",
    "    dropout_rate=0.2,\n",
    "    drop_connect_rate=0.2,\n",
    "    depth_divisor=8,\n",
    "    activation=\"swish\",\n",
    "    blocks_args=\"default\",\n",
    "    model_name=\"efficientnet\",\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "):\n",
    "    \"\"\"Instantiates the EfficientNet architecture.\n",
    "\n",
    "    Args:\n",
    "      width_coefficient: float, scaling coefficient for network width.\n",
    "      depth_coefficient: float, scaling coefficient for network depth.\n",
    "      default_size: integer, default input image size.\n",
    "      dropout_rate: float, dropout rate before final classifier layer.\n",
    "      drop_connect_rate: float, dropout rate at skip connections.\n",
    "      depth_divisor: integer, a unit of network width.\n",
    "      activation: activation function.\n",
    "      blocks_args: list of dicts, parameters to construct block modules.\n",
    "      model_name: string, model name.\n",
    "      include_top: whether to include the fully-connected\n",
    "          layer at the top of the network.\n",
    "      weights: one of `None` (random initialization),\n",
    "            'imagenet' (pre-training on ImageNet),\n",
    "            or the path to the weights file to be loaded.\n",
    "      input_tensor: optional Keras tensor\n",
    "          (i.e. output of `layers.Input()`)\n",
    "          to use as image input for the model.\n",
    "      input_shape: optional shape tuple, only to be specified\n",
    "          if `include_top` is False.\n",
    "          It should have exactly 3 inputs channels.\n",
    "      pooling: optional pooling mode for feature extraction\n",
    "          when `include_top` is `False`.\n",
    "          - `None` means that the output of the model will be\n",
    "              the 4D tensor output of the\n",
    "              last convolutional layer.\n",
    "          - `avg` means that global average pooling\n",
    "              will be applied to the output of the\n",
    "              last convolutional layer, and thus\n",
    "              the output of the model will be a 2D tensor.\n",
    "          - `max` means that global max pooling will\n",
    "              be applied.\n",
    "      classes: optional number of classes to classify images\n",
    "          into, only to be specified if `include_top` is True, and\n",
    "          if no `weights` argument is specified.\n",
    "      classifier_activation: A `str` or callable. The activation function to use\n",
    "          on the \"top\" layer. Ignored unless `include_top=True`. Set\n",
    "          `classifier_activation=None` to return the logits of the \"top\" layer.\n",
    "\n",
    "    Returns:\n",
    "        A model instance.\n",
    "    \"\"\"\n",
    "    if blocks_args == \"default\":\n",
    "        blocks_args = DEFAULT_BLOCKS_ARGS\n",
    "\n",
    "    if not (weights in {\"imagenet\", None} or file_utils.exists(weights)):\n",
    "        raise ValueError(\n",
    "            \"The `weights` argument should be either \"\n",
    "            \"`None` (random initialization), `imagenet` \"\n",
    "            \"(pre-training on ImageNet), \"\n",
    "            \"or the path to the weights file to be loaded.\"\n",
    "        )\n",
    "\n",
    "    if weights == \"imagenet\" and include_top and classes != 1000:\n",
    "        raise ValueError(\n",
    "            'If using `weights=\"imagenet\"` with `include_top`'\n",
    "            \" as true, `classes` should be 1000\"\n",
    "        )\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = imagenet_utils.obtain_input_shape(\n",
    "        input_shape,\n",
    "        default_size=default_size,\n",
    "        min_size=32,\n",
    "        data_format=backend.image_data_format(),\n",
    "        require_flatten=include_top,\n",
    "        weights=weights,\n",
    "    )\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    bn_axis = 3 if backend.image_data_format() == \"channels_last\" else 1\n",
    "\n",
    "    def round_filters(filters, divisor=depth_divisor):\n",
    "        \"\"\"Round number of filters based on depth multiplier.\"\"\"\n",
    "        filters *= width_coefficient\n",
    "        new_filters = max(\n",
    "            divisor, int(filters + divisor / 2) // divisor * divisor\n",
    "        )\n",
    "        # Make sure that round down does not go down by more than 10%.\n",
    "        if new_filters < 0.9 * filters:\n",
    "            new_filters += divisor\n",
    "        return int(new_filters)\n",
    "\n",
    "    def round_repeats(repeats):\n",
    "        \"\"\"Round number of repeats based on depth multiplier.\"\"\"\n",
    "        return int(math.ceil(depth_coefficient * repeats))\n",
    "\n",
    "    # Build stem\n",
    "    x = img_input\n",
    "    x = layers.Rescaling(1.0 / 255.0)(x)\n",
    "    x = layers.Normalization(axis=bn_axis)(x)\n",
    "    if weights == \"imagenet\":\n",
    "        # Note that the normaliztion layer uses square value of STDDEV as the\n",
    "        # variance for the layer: result = (input - mean) / sqrt(var)\n",
    "        # However, the original implemenetation uses (input - mean) / var to\n",
    "        # normalize the input, we need to divide another sqrt(var) to match the\n",
    "        # original implementation.\n",
    "        # See https://github.com/tensorflow/tensorflow/issues/49930 for more\n",
    "        # details\n",
    "        x = layers.Rescaling(\n",
    "            [1.0 / math.sqrt(stddev) for stddev in IMAGENET_STDDEV_RGB]\n",
    "        )(x)\n",
    "\n",
    "    x = layers.ZeroPadding2D(\n",
    "        padding=imagenet_utils.correct_pad(x, 3), name=\"stem_conv_pad\"\n",
    "    )(x)\n",
    "    x = layers.Conv2D(\n",
    "        round_filters(32),\n",
    "        3,\n",
    "        strides=2,\n",
    "        padding=\"valid\",\n",
    "        use_bias=False,\n",
    "        kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        name=\"stem_conv\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=\"stem_bn\")(x)\n",
    "    x = layers.Activation(activation, name=\"stem_activation\")(x)\n",
    "\n",
    "    # Build blocks\n",
    "    blocks_args = copy.deepcopy(blocks_args)\n",
    "\n",
    "    b = 0\n",
    "    blocks = float(sum(round_repeats(args[\"repeats\"]) for args in blocks_args))\n",
    "    for i, args in enumerate(blocks_args):\n",
    "        assert args[\"repeats\"] > 0\n",
    "        # Update block input and output filters based on depth multiplier.\n",
    "        args[\"filters_in\"] = round_filters(args[\"filters_in\"])\n",
    "        args[\"filters_out\"] = round_filters(args[\"filters_out\"])\n",
    "\n",
    "        for j in range(round_repeats(args.pop(\"repeats\"))):\n",
    "            # The first block needs to take care of stride and filter size\n",
    "            # increase.\n",
    "            if j > 0:\n",
    "                args[\"strides\"] = 1\n",
    "                args[\"filters_in\"] = args[\"filters_out\"]\n",
    "            x = block(\n",
    "                x,\n",
    "                activation,\n",
    "                drop_connect_rate * b / blocks,\n",
    "                name=f\"block{i + 1}{chr(j + 97)}_\",\n",
    "                **args,\n",
    "            )\n",
    "            b += 1\n",
    "\n",
    "    # Build top\n",
    "    x = layers.Conv2D(\n",
    "        round_filters(1280),\n",
    "        1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        name=\"top_conv\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=\"top_bn\")(x)\n",
    "    x = layers.Activation(activation, name=\"top_activation\")(x)\n",
    "    if include_top:\n",
    "        x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "        if dropout_rate > 0:\n",
    "            x = layers.Dropout(dropout_rate, name=\"top_dropout\")(x)\n",
    "        imagenet_utils.validate_activation(classifier_activation, weights)\n",
    "        x = layers.Dense(\n",
    "            classes,\n",
    "            activation=classifier_activation,\n",
    "            kernel_initializer=DENSE_KERNEL_INITIALIZER,\n",
    "            name=\"predictions\",\n",
    "        )(x)\n",
    "    else:\n",
    "        if pooling == \"avg\":\n",
    "            x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "        elif pooling == \"max\":\n",
    "            x = layers.GlobalMaxPooling2D(name=\"max_pool\")(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = operation_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Create model.\n",
    "    model = Functional(inputs, x, name=model_name)\n",
    "\n",
    "    # Load weights.\n",
    "    if weights == \"imagenet\":\n",
    "        if include_top:\n",
    "            file_suffix = \".h5\"\n",
    "            file_hash = WEIGHTS_HASHES[model_name[-2:]][0]\n",
    "        else:\n",
    "            file_suffix = \"_notop.h5\"\n",
    "            file_hash = WEIGHTS_HASHES[model_name[-2:]][1]\n",
    "        file_name = model_name + file_suffix\n",
    "        weights_path = file_utils.get_file(\n",
    "            file_name,\n",
    "            BASE_WEIGHTS_PATH + file_name,\n",
    "            cache_subdir=\"models\",\n",
    "            file_hash=file_hash,\n",
    "        )\n",
    "        model.load_weights(weights_path)\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "    return model\n",
    "\n",
    "\n",
    "def block(\n",
    "    inputs,\n",
    "    activation=\"swish\",\n",
    "    drop_rate=0.0,\n",
    "    name=\"\",\n",
    "    filters_in=32,\n",
    "    filters_out=16,\n",
    "    kernel_size=3,\n",
    "    strides=1,\n",
    "    expand_ratio=1,\n",
    "    se_ratio=0.0,\n",
    "    id_skip=True,\n",
    "):\n",
    "    \"\"\"An inverted residual block.\n",
    "\n",
    "    Args:\n",
    "        inputs: input tensor.\n",
    "        activation: activation function.\n",
    "        drop_rate: float between 0 and 1, fraction of the input units to drop.\n",
    "        name: string, block label.\n",
    "        filters_in: integer, the number of input filters.\n",
    "        filters_out: integer, the number of output filters.\n",
    "        kernel_size: integer, the dimension of the convolution window.\n",
    "        strides: integer, the stride of the convolution.\n",
    "        expand_ratio: integer, scaling coefficient for the input filters.\n",
    "        se_ratio: float between 0 and 1, fraction to squeeze the input filters.\n",
    "        id_skip: boolean.\n",
    "\n",
    "    Returns:\n",
    "        output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3 if backend.image_data_format() == \"channels_last\" else 1\n",
    "\n",
    "    # Expansion phase\n",
    "    filters = filters_in * expand_ratio\n",
    "    if expand_ratio != 1:\n",
    "        x = layers.Conv2D(\n",
    "            filters,\n",
    "            1,\n",
    "            padding=\"same\",\n",
    "            use_bias=False,\n",
    "            kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "            name=name + \"expand_conv\",\n",
    "        )(inputs)\n",
    "        x = layers.BatchNormalization(axis=bn_axis, name=name + \"expand_bn\")(x)\n",
    "        x = layers.Activation(activation, name=name + \"expand_activation\")(x)\n",
    "    else:\n",
    "        x = inputs\n",
    "\n",
    "    # Depthwise Convolution\n",
    "    if strides == 2:\n",
    "        x = layers.ZeroPadding2D(\n",
    "            padding=imagenet_utils.correct_pad(x, kernel_size),\n",
    "            name=name + \"dwconv_pad\",\n",
    "        )(x)\n",
    "        conv_pad = \"valid\"\n",
    "    else:\n",
    "        conv_pad = \"same\"\n",
    "    x = layers.DepthwiseConv2D(\n",
    "        kernel_size,\n",
    "        strides=strides,\n",
    "        padding=conv_pad,\n",
    "        use_bias=False,\n",
    "        depthwise_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        name=name + \"dwconv\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=name + \"bn\")(x)\n",
    "    x = layers.Activation(activation, name=name + \"activation\")(x)\n",
    "\n",
    "    # Squeeze and Excitation phase\n",
    "    if 0 < se_ratio <= 1:\n",
    "        filters_se = max(1, int(filters_in * se_ratio))\n",
    "        se = layers.GlobalAveragePooling2D(name=name + \"se_squeeze\")(x)\n",
    "        if bn_axis == 1:\n",
    "            se_shape = (filters, 1, 1)\n",
    "        else:\n",
    "            se_shape = (1, 1, filters)\n",
    "        se = layers.Reshape(se_shape, name=name + \"se_reshape\")(se)\n",
    "        se = layers.Conv2D(\n",
    "            filters_se,\n",
    "            1,\n",
    "            padding=\"same\",\n",
    "            activation=activation,\n",
    "            kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "            name=name + \"se_reduce\",\n",
    "        )(se)\n",
    "        se = layers.Conv2D(\n",
    "            filters,\n",
    "            1,\n",
    "            padding=\"same\",\n",
    "            activation=\"sigmoid\",\n",
    "            kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "            name=name + \"se_expand\",\n",
    "        )(se)\n",
    "        x = layers.multiply([x, se], name=name + \"se_excite\")\n",
    "\n",
    "    # Output phase\n",
    "    x = layers.Conv2D(\n",
    "        filters_out,\n",
    "        1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        name=name + \"project_conv\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=name + \"project_bn\")(x)\n",
    "    if id_skip and strides == 1 and filters_in == filters_out:\n",
    "        if drop_rate > 0:\n",
    "            x = layers.Dropout(\n",
    "                drop_rate, noise_shape=(None, 1, 1, 1), name=name + \"drop\"\n",
    "            )(x)\n",
    "        x = layers.add([x, inputs], name=name + \"add\")\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\n",
    "    [\n",
    "        \"keras.applications.efficientnet.EfficientNetB0\",\n",
    "        \"keras.applications.EfficientNetB0\",\n",
    "    ]\n",
    ")\n",
    "def EfficientNetB0(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs,\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.0,\n",
    "        1.0,\n",
    "        224,\n",
    "        0.2,\n",
    "        model_name=\"efficientnetb0\",\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        classes=classes,\n",
    "        classifier_activation=classifier_activation,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "@keras_export(\n",
    "    [\n",
    "        \"keras.applications.efficientnet.EfficientNetB1\",\n",
    "        \"keras.applications.EfficientNetB1\",\n",
    "    ]\n",
    ")\n",
    "def EfficientNetB1(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs,\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.0,\n",
    "        1.1,\n",
    "        240,\n",
    "        0.2,\n",
    "        model_name=\"efficientnetb1\",\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        classes=classes,\n",
    "        classifier_activation=classifier_activation,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "@keras_export(\n",
    "    [\n",
    "        \"keras.applications.efficientnet.EfficientNetB2\",\n",
    "        \"keras.applications.EfficientNetB2\",\n",
    "    ]\n",
    ")\n",
    "def EfficientNetB2(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs,\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.1,\n",
    "        1.2,\n",
    "        260,\n",
    "        0.3,\n",
    "        model_name=\"efficientnetb2\",\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        classes=classes,\n",
    "        classifier_activation=classifier_activation,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "@keras_export(\n",
    "    [\n",
    "        \"keras.applications.efficientnet.EfficientNetB3\",\n",
    "        \"keras.applications.EfficientNetB3\",\n",
    "    ]\n",
    ")\n",
    "def EfficientNetB3(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs,\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.2,\n",
    "        1.4,\n",
    "        300,\n",
    "        0.3,\n",
    "        model_name=\"efficientnetb3\",\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        classes=classes,\n",
    "        classifier_activation=classifier_activation,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "@keras_export(\n",
    "    [\n",
    "        \"keras.applications.efficientnet.EfficientNetB4\",\n",
    "        \"keras.applications.EfficientNetB4\",\n",
    "    ]\n",
    ")\n",
    "def EfficientNetB4(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs,\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.4,\n",
    "        1.8,\n",
    "        380,\n",
    "        0.4,\n",
    "        model_name=\"efficientnetb4\",\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        classes=classes,\n",
    "        classifier_activation=classifier_activation,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "@keras_export(\n",
    "    [\n",
    "        \"keras.applications.efficientnet.EfficientNetB5\",\n",
    "        \"keras.applications.EfficientNetB5\",\n",
    "    ]\n",
    ")\n",
    "def EfficientNetB5(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs,\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.6,\n",
    "        2.2,\n",
    "        456,\n",
    "        0.4,\n",
    "        model_name=\"efficientnetb5\",\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        classes=classes,\n",
    "        classifier_activation=classifier_activation,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "@keras_export(\n",
    "    [\n",
    "        \"keras.applications.efficientnet.EfficientNetB6\",\n",
    "        \"keras.applications.EfficientNetB6\",\n",
    "    ]\n",
    ")\n",
    "def EfficientNetB6(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs,\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.8,\n",
    "        2.6,\n",
    "        528,\n",
    "        0.5,\n",
    "        model_name=\"efficientnetb6\",\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        classes=classes,\n",
    "        classifier_activation=classifier_activation,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "@keras_export(\n",
    "    [\n",
    "        \"keras.applications.efficientnet.EfficientNetB7\",\n",
    "        \"keras.applications.EfficientNetB7\",\n",
    "    ]\n",
    ")\n",
    "def EfficientNetB7(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs,\n",
    "):\n",
    "    return EfficientNet(\n",
    "        2.0,\n",
    "        3.1,\n",
    "        600,\n",
    "        0.5,\n",
    "        model_name=\"efficientnetb7\",\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        classes=classes,\n",
    "        classifier_activation=classifier_activation,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "EfficientNetB0.__doc__ = BASE_DOCSTRING.format(name=\"EfficientNetB0\")\n",
    "EfficientNetB1.__doc__ = BASE_DOCSTRING.format(name=\"EfficientNetB1\")\n",
    "EfficientNetB2.__doc__ = BASE_DOCSTRING.format(name=\"EfficientNetB2\")\n",
    "EfficientNetB3.__doc__ = BASE_DOCSTRING.format(name=\"EfficientNetB3\")\n",
    "EfficientNetB4.__doc__ = BASE_DOCSTRING.format(name=\"EfficientNetB4\")\n",
    "EfficientNetB5.__doc__ = BASE_DOCSTRING.format(name=\"EfficientNetB5\")\n",
    "EfficientNetB6.__doc__ = BASE_DOCSTRING.format(name=\"EfficientNetB6\")\n",
    "EfficientNetB7.__doc__ = BASE_DOCSTRING.format(name=\"EfficientNetB7\")\n",
    "\n",
    "\n",
    "@keras_export(\"keras.applications.efficientnet.preprocess_input\")\n",
    "def preprocess_input(x, data_format=None):\n",
    "    \"\"\"A placeholder method for backward compatibility.\n",
    "\n",
    "    The preprocessing logic has been included in the efficientnet model\n",
    "    implementation. Users are no longer required to call this method to\n",
    "    normalize the input data. This method does nothing and only kept as a\n",
    "    placeholder to align the API surface between old and new version of model.\n",
    "\n",
    "    Args:\n",
    "        x: A floating point `numpy.array` or a tensor.\n",
    "        data_format: Optional data format of the image tensor/array. `None`\n",
    "            means the global setting `keras.backend.image_data_format()`\n",
    "            is used (unless you changed it, it uses `\"channels_last\"`).\n",
    "            Defaults to `None`.\n",
    "\n",
    "    Returns:\n",
    "        Unchanged `numpy.array` or tensor.\n",
    "    \"\"\"\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\"keras.applications.efficientnet.decode_predictions\")\n",
    "def decode_predictions(preds, top=5):\n",
    "    return imagenet_utils.decode_predictions(preds, top=top)\n",
    "\n",
    "\n",
    "decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c3b733-3bd9-4a4f-b60f-c2180b2aff88",
   "metadata": {},
   "source": [
    "## Define Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6042ca74-ad16-4d1b-b6d9-824d0e321199",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def augment_and_resize_dataset(base_path, img_size, batch_size, preprocess_input_func=None):\n",
    "    train_path = os.path.join(base_path, 'train')\n",
    "    validation_path = os.path.join(base_path, 'val')\n",
    "    test_path = os.path.join(base_path, 'test')\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input_func,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    # Untuk data validation dan test, hanya preprocessing\n",
    "    validation_test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_func)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    validation_generator = validation_test_datagen.flow_from_directory(\n",
    "        validation_path,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    test_generator = validation_test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_generator, validation_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ffad30e-3d81-4ec8-864d-fa0efbd7913a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Fungsi untuk melatih model dan menampilkan grafik serta menyimpannya\n",
    "def train_and_plot(model, model_name, train_generator, validation_generator, test_generator, epochs):\n",
    "    # Callback untuk menghentikan pelatihan jika tidak ada perbaikan setelah beberapa epoch\n",
    "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Menghitung waktu mulai pelatihan\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Melatih model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=validation_generator,\n",
    "        epochs=epochs,\n",
    "        callbacks=[early_stopping_callback]\n",
    "    )\n",
    "    \n",
    "    # Menghitung waktu selesai pelatihan\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Menghitung durasi pelatihan\n",
    "    training_duration = end_time - start_time  # dalam detik\n",
    "\n",
    "    # Plotting hasil akurasi\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot training & validation accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'{model_name} Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'{model_name} Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # Tampilkan plot\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluasi model pada data test\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Prediksi pada data test\n",
    "    y_pred = model.predict(test_generator)\n",
    "\n",
    "    # Mengambil index dari prediksi (kelas dengan probabilitas tertinggi)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Mengambil label sebenarnya dari generator\n",
    "    y_true = test_generator.classes\n",
    "\n",
    "    # Membuat confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    class_names = list(test_generator.class_indices.keys())\n",
    "\n",
    "    # Menampilkan classification report\n",
    "    print(\"Classification Report:\\n\", classification_report(y_true, y_pred_classes, target_names=class_names))\n",
    "\n",
    "    # Plot confusion matrix sebagai heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    # Tampilkan confusion matrix\n",
    "    plt.show()\n",
    "\n",
    "    return history, test_loss, test_accuracy, training_duration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459c9ebe-90f3-4a32-a9c4-d6afcb797960",
   "metadata": {},
   "source": [
    "## Training menggunakan EfficientNet Not Modified Weights imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50dbbc51-7dfa-4297-912f-ae6a389917dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 14:28:42.940407: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> \n",
       "\n",
       " global_average_pooling2d         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)                                               \n",
       "\n",
       " batch_normalization              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> \n",
       "\n",
       " batch_normalization_1            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> \n",
       "\n",
       " batch_normalization_2            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          \u001b[38;5;34m4,049,571\u001b[0m \n",
       "\n",
       " global_average_pooling2d         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                        \u001b[38;5;34m0\u001b[0m \n",
       " (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)                                               \n",
       "\n",
       " batch_normalization              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                    \u001b[38;5;34m5,120\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                   \u001b[38;5;34m327,936\u001b[0m \n",
       "\n",
       " batch_normalization_1            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                     \u001b[38;5;34m1,024\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m32,896\u001b[0m \n",
       "\n",
       " batch_normalization_2            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                       \u001b[38;5;34m512\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_2 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                         \u001b[38;5;34m387\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,417,446</span> (16.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,417,446\u001b[0m (16.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,063,435</span> (15.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,063,435\u001b[0m (15.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">354,011</span> (1.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m354,011\u001b[0m (1.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = EfficientNetB0(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
    "model.trainable = True\n",
    "\n",
    "# Freeze 50% layer pertama dari base model\n",
    "total_layers = len(model.layers)\n",
    "freeze_layers = int(0.50 * total_layers)\n",
    "for layer in model.layers[:freeze_layers]:\n",
    "    layer.trainable = False\n",
    "\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "\n",
    "x = model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "outputs = Dense(3, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f994f4da-1ace-40d7-86cd-2ba78096c503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1382 images belonging to 3 classes.\n",
      "Found 348 images belonging to 3 classes.\n",
      "Found 2550 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m31/87\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 936ms/step - accuracy: 0.3944 - loss: 1.5393"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m train_generator, validation_generator, test_generator \u001b[38;5;241m=\u001b[39m augment_and_resize_dataset(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/split_train_test_dataset_campuran\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     img_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m),\n\u001b[1;32m      4\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m      5\u001b[0m     preprocess_input_func \u001b[38;5;241m=\u001b[39m efficientnet_preprocess\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m history_EN_B0, test_loss, test_acc, training_duration \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEfficientNetB0_Custom\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m, in \u001b[0;36mtrain_and_plot\u001b[0;34m(model, model_name, train_generator, validation_generator, test_generator, epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Melatih model\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_callback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Menghitung waktu selesai pelatihan\u001b[39;00m\n\u001b[1;32m     18\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_generator, validation_generator, test_generator = augment_and_resize_dataset(\n",
    "    \"data/split_train_test_dataset_campuran\",\n",
    "    img_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    preprocess_input_func = efficientnet_preprocess\n",
    ")\n",
    "\n",
    "history_EN_B0, test_loss, test_acc, training_duration = train_and_plot(model, \"EfficientNetB0_Custom\", train_generator, validation_generator, test_generator, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5553e220-f365-47f7-853e-9413ca9fbb58",
   "metadata": {},
   "source": [
    "## Training menggunakan EfficientNet Not Modified Weights None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d273d0c-391b-421e-aba5-2626cf063367",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = EfficientNetB0(input_shape=(224, 224, 3), include_top=False, weights=None)\n",
    "model.trainable = True\n",
    "\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "\n",
    "x = model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "outputs = Dense(3, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc38515-11f3-48a9-bc7f-9b7346bc63c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator, validation_generator, test_generator = augment_and_resize_dataset(\n",
    "    \"data/split_train_test_dataset_campuran\",\n",
    "    img_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    preprocess_input_func = efficientnet_preprocess\n",
    ")\n",
    "\n",
    "history_EN_B0, test_loss, test_acc, training_duration = train_and_plot(model, \"EfficientNetB0_Custom\", train_generator, validation_generator, test_generator, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef89c6b-2423-4763-abee-f6f8bb794709",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetB7(input_shape=(600, 600, 3), include_top=False, weights=None)\n",
    "model.trainable = True\n",
    "\n",
    "inputs = Input(shape=(600, 600, 3))\n",
    "\n",
    "x = model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "outputs = Dense(3, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19adeb-8c87-4b82-ab19-83643f1288d5",
   "metadata": {},
   "source": [
    "# EfficientNet Modified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d0ac4e-2505-47b0-93a5-b9f63529d358",
   "metadata": {},
   "source": [
    "## Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c75bcf-980b-4912-9ec9-a7a9924e2a90",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "\n",
    "from keras.src import backend\n",
    "from keras.src import layers\n",
    "from keras.src.api_export import keras_export\n",
    "from keras.src.applications import imagenet_utils\n",
    "from keras.src.models import Functional\n",
    "from keras.src.ops import operation_utils\n",
    "from keras.src.utils import file_utils\n",
    "\n",
    "BASE_WEIGHTS_PATH = \"https://storage.googleapis.com/keras-applications/\"\n",
    "\n",
    "WEIGHTS_HASHES = {\n",
    "    \"b0\": (\n",
    "        \"902e53a9f72be733fc0bcb005b3ebbac\",\n",
    "        \"50bc09e76180e00e4465e1a485ddc09d\",\n",
    "    ),\n",
    "    \"b1\": (\n",
    "        \"1d254153d4ab51201f1646940f018540\",\n",
    "        \"74c4e6b3e1f6a1eea24c589628592432\",\n",
    "    ),\n",
    "    \"b2\": (\n",
    "        \"b15cce36ff4dcbd00b6dd88e7857a6ad\",\n",
    "        \"111f8e2ac8aa800a7a99e3239f7bfb39\",\n",
    "    ),\n",
    "    \"b3\": (\n",
    "        \"ffd1fdc53d0ce67064dc6a9c7960ede0\",\n",
    "        \"af6d107764bb5b1abb91932881670226\",\n",
    "    ),\n",
    "    \"b4\": (\n",
    "        \"18c95ad55216b8f92d7e70b3a046e2fc\",\n",
    "        \"ebc24e6d6c33eaebbd558eafbeedf1ba\",\n",
    "    ),\n",
    "    \"b5\": (\n",
    "        \"ace28f2a6363774853a83a0b21b9421a\",\n",
    "        \"38879255a25d3c92d5e44e04ae6cec6f\",\n",
    "    ),\n",
    "    \"b6\": (\n",
    "        \"165f6e37dce68623721b423839de8be5\",\n",
    "        \"9ecce42647a20130c1f39a5d4cb75743\",\n",
    "    ),\n",
    "    \"b7\": (\n",
    "        \"8c03f828fec3ef71311cd463b6759d99\",\n",
    "        \"cbcfe4450ddf6f3ad90b1b398090fe4a\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "DEFAULT_BLOCKS_ARGS = [\n",
    "    {\n",
    "        \"kernel_size\": 3,\n",
    "        \"repeats\": 1,\n",
    "        \"filters_in\": 32,\n",
    "        \"filters_out\": 16,\n",
    "        \"expand_ratio\": 1,\n",
    "        \"id_skip\": True,\n",
    "        \"strides\": 1,\n",
    "        \"se_ratio\": 0.25,\n",
    "    },\n",
    "    {\n",
    "        \"kernel_size\": 3,\n",
    "        \"repeats\": 1,\n",
    "        \"filters_in\": 16,\n",
    "        \"filters_out\": 24,\n",
    "        \"expand_ratio\": 6,\n",
    "        \"id_skip\": True,\n",
    "        \"strides\": 2,\n",
    "        \"se_ratio\": 0.25,\n",
    "    },\n",
    "    {\n",
    "        \"kernel_size\": 5,\n",
    "        \"repeats\": 1,\n",
    "        \"filters_in\": 24,\n",
    "        \"filters_out\": 40,\n",
    "        \"expand_ratio\": 6,\n",
    "        \"id_skip\": True,\n",
    "        \"strides\": 2,\n",
    "        \"se_ratio\": 0.25,\n",
    "    },\n",
    "    {\n",
    "        \"kernel_size\": 3,\n",
    "        \"repeats\": 1,\n",
    "        \"filters_in\": 40,\n",
    "        \"filters_out\": 80,\n",
    "        \"expand_ratio\": 6,\n",
    "        \"id_skip\": True,\n",
    "        \"strides\": 2,\n",
    "        \"se_ratio\": 0.25,\n",
    "    },\n",
    "    {\n",
    "        \"kernel_size\": 5,\n",
    "        \"repeats\": 1,\n",
    "        \"filters_in\": 80,\n",
    "        \"filters_out\": 112,\n",
    "        \"expand_ratio\": 6,\n",
    "        \"id_skip\": True,\n",
    "        \"strides\": 1,\n",
    "        \"se_ratio\": 0.25,\n",
    "    },\n",
    "    {\n",
    "        \"kernel_size\": 5,\n",
    "        \"repeats\": 1,\n",
    "        \"filters_in\": 112,\n",
    "        \"filters_out\": 192,\n",
    "        \"expand_ratio\": 6,\n",
    "        \"id_skip\": True,\n",
    "        \"strides\": 2,\n",
    "        \"se_ratio\": 0.25,\n",
    "    },\n",
    "    {\n",
    "        \"kernel_size\": 3,\n",
    "        \"repeats\": 1,\n",
    "        \"filters_in\": 192,\n",
    "        \"filters_out\": 320,\n",
    "        \"expand_ratio\": 6,\n",
    "        \"id_skip\": True,\n",
    "        \"strides\": 1,\n",
    "        \"se_ratio\": 0.25,\n",
    "    },\n",
    "]\n",
    "\n",
    "CONV_KERNEL_INITIALIZER = {\n",
    "    \"class_name\": \"VarianceScaling\",\n",
    "    \"config\": {\n",
    "        \"scale\": 2.0,\n",
    "        \"mode\": \"fan_out\",\n",
    "        \"distribution\": \"truncated_normal\",\n",
    "    },\n",
    "}\n",
    "\n",
    "DENSE_KERNEL_INITIALIZER = {\n",
    "    \"class_name\": \"VarianceScaling\",\n",
    "    \"config\": {\n",
    "        \"scale\": 1.0 / 3.0,\n",
    "        \"mode\": \"fan_out\",\n",
    "        \"distribution\": \"uniform\",\n",
    "    },\n",
    "}\n",
    "\n",
    "BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n",
    "\n",
    "Reference:\n",
    "- [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](\n",
    "    https://arxiv.org/abs/1905.11946) (ICML 2019)\n",
    "\n",
    "This function returns a Keras image classification model,\n",
    "optionally loaded with weights pre-trained on ImageNet.\n",
    "\n",
    "For image classification use cases, see\n",
    "[this page for detailed examples](\n",
    "https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n",
    "\n",
    "For transfer learning use cases, make sure to read the\n",
    "[guide to transfer learning & fine-tuning](\n",
    "https://keras.io/guides/transfer_learning/).\n",
    "\n",
    "Note: each Keras Application expects a specific kind of input preprocessing.\n",
    "For EfficientNet, input preprocessing is included as part of the model\n",
    "(as a `Rescaling` layer), and thus\n",
    "`keras.applications.efficientnet.preprocess_input` is actually a\n",
    "pass-through function. EfficientNet models expect their inputs to be float\n",
    "tensors of pixels with values in the `[0-255]` range.\n",
    "\n",
    "Args:\n",
    "    include_top: Whether to include the fully-connected\n",
    "        layer at the top of the network. Defaults to `True`.\n",
    "    weights: One of `None` (random initialization),\n",
    "        `\"imagenet\"` (pre-training on ImageNet),\n",
    "        or the path to the weights file to be loaded.\n",
    "        Defaults to `\"imagenet\"`.\n",
    "    input_tensor: Optional Keras tensor\n",
    "        (i.e. output of `layers.Input()`)\n",
    "        to use as image input for the model.\n",
    "    input_shape: Optional shape tuple, only to be specified\n",
    "        if `include_top` is False.\n",
    "        It should have exactly 3 inputs channels.\n",
    "    pooling: Optional pooling mode for feature extraction\n",
    "        when `include_top` is `False`. Defaults to `None`.\n",
    "        - `None` means that the output of the model will be\n",
    "            the 4D tensor output of the\n",
    "            last convolutional layer.\n",
    "        - `avg` means that global average pooling\n",
    "            will be applied to the output of the\n",
    "            last convolutional layer, and thus\n",
    "            the output of the model will be a 2D tensor.\n",
    "        - `max` means that global max pooling will\n",
    "            be applied.\n",
    "    classes: Optional number of classes to classify images\n",
    "        into, only to be specified if `include_top` is True, and\n",
    "        if no `weights` argument is specified. 1000 is how many\n",
    "        ImageNet classes there are. Defaults to `1000`.\n",
    "    classifier_activation: A `str` or callable. The activation function to use\n",
    "        on the \"top\" layer. Ignored unless `include_top=True`. Set\n",
    "        `classifier_activation=None` to return the logits of the \"top\" layer.\n",
    "        Defaults to `'softmax'`.\n",
    "        When loading pretrained weights, `classifier_activation` can only\n",
    "        be `None` or `\"softmax\"`.\n",
    "\n",
    "Returns:\n",
    "    A model instance.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "IMAGENET_STDDEV_RGB = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "def EfficientNet(\n",
    "    width_coefficient,\n",
    "    depth_coefficient,\n",
    "    default_size,\n",
    "    dropout_rate=0.2,\n",
    "    drop_connect_rate=0.2,\n",
    "    depth_divisor=8,\n",
    "    activation=\"swish\",\n",
    "    blocks_args=\"default\",\n",
    "    model_name=\"efficientnet\",\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "):\n",
    "    \"\"\"Instantiates the EfficientNet architecture.\n",
    "\n",
    "    Args:\n",
    "      width_coefficient: float, scaling coefficient for network width.\n",
    "      depth_coefficient: float, scaling coefficient for network depth.\n",
    "      default_size: integer, default input image size.\n",
    "      dropout_rate: float, dropout rate before final classifier layer.\n",
    "      drop_connect_rate: float, dropout rate at skip connections.\n",
    "      depth_divisor: integer, a unit of network width.\n",
    "      activation: activation function.\n",
    "      blocks_args: list of dicts, parameters to construct block modules.\n",
    "      model_name: string, model name.\n",
    "      include_top: whether to include the fully-connected\n",
    "          layer at the top of the network.\n",
    "      weights: one of `None` (random initialization),\n",
    "            'imagenet' (pre-training on ImageNet),\n",
    "            or the path to the weights file to be loaded.\n",
    "      input_tensor: optional Keras tensor\n",
    "          (i.e. output of `layers.Input()`)\n",
    "          to use as image input for the model.\n",
    "      input_shape: optional shape tuple, only to be specified\n",
    "          if `include_top` is False.\n",
    "          It should have exactly 3 inputs channels.\n",
    "      pooling: optional pooling mode for feature extraction\n",
    "          when `include_top` is `False`.\n",
    "          - `None` means that the output of the model will be\n",
    "              the 4D tensor output of the\n",
    "              last convolutional layer.\n",
    "          - `avg` means that global average pooling\n",
    "              will be applied to the output of the\n",
    "              last convolutional layer, and thus\n",
    "              the output of the model will be a 2D tensor.\n",
    "          - `max` means that global max pooling will\n",
    "              be applied.\n",
    "      classes: optional number of classes to classify images\n",
    "          into, only to be specified if `include_top` is True, and\n",
    "          if no `weights` argument is specified.\n",
    "      classifier_activation: A `str` or callable. The activation function to use\n",
    "          on the \"top\" layer. Ignored unless `include_top=True`. Set\n",
    "          `classifier_activation=None` to return the logits of the \"top\" layer.\n",
    "\n",
    "    Returns:\n",
    "        A model instance.\n",
    "    \"\"\"\n",
    "    if blocks_args == \"default\":\n",
    "        blocks_args = DEFAULT_BLOCKS_ARGS\n",
    "\n",
    "    if not (weights in {\"imagenet\", None} or file_utils.exists(weights)):\n",
    "        raise ValueError(\n",
    "            \"The `weights` argument should be either \"\n",
    "            \"`None` (random initialization), `imagenet` \"\n",
    "            \"(pre-training on ImageNet), \"\n",
    "            \"or the path to the weights file to be loaded.\"\n",
    "        )\n",
    "\n",
    "    if weights == \"imagenet\" and include_top and classes != 1000:\n",
    "        raise ValueError(\n",
    "            'If using `weights=\"imagenet\"` with `include_top`'\n",
    "            \" as true, `classes` should be 1000\"\n",
    "        )\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = imagenet_utils.obtain_input_shape(\n",
    "        input_shape,\n",
    "        default_size=default_size,\n",
    "        min_size=32,\n",
    "        data_format=backend.image_data_format(),\n",
    "        require_flatten=include_top,\n",
    "        weights=weights,\n",
    "    )\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    bn_axis = 3 if backend.image_data_format() == \"channels_last\" else 1\n",
    "\n",
    "    def round_filters(filters, divisor=depth_divisor):\n",
    "        \"\"\"Round number of filters based on depth multiplier.\"\"\"\n",
    "        filters *= width_coefficient\n",
    "        new_filters = max(\n",
    "            divisor, int(filters + divisor / 2) // divisor * divisor\n",
    "        )\n",
    "        # Make sure that round down does not go down by more than 10%.\n",
    "        if new_filters < 0.9 * filters:\n",
    "            new_filters += divisor\n",
    "        return int(new_filters)\n",
    "\n",
    "    def round_repeats(repeats):\n",
    "        \"\"\"Round number of repeats based on depth multiplier.\"\"\"\n",
    "        return int(math.ceil(depth_coefficient * repeats))\n",
    "\n",
    "    # Build stem\n",
    "    x = img_input\n",
    "    x = layers.Rescaling(1.0 / 255.0)(x)\n",
    "    x = layers.Normalization(axis=bn_axis)(x)\n",
    "    if weights == \"imagenet\":\n",
    "        # Note that the normaliztion layer uses square value of STDDEV as the\n",
    "        # variance for the layer: result = (input - mean) / sqrt(var)\n",
    "        # However, the original implemenetation uses (input - mean) / var to\n",
    "        # normalize the input, we need to divide another sqrt(var) to match the\n",
    "        # original implementation.\n",
    "        # See https://github.com/tensorflow/tensorflow/issues/49930 for more\n",
    "        # details\n",
    "        x = layers.Rescaling(\n",
    "            [1.0 / math.sqrt(stddev) for stddev in IMAGENET_STDDEV_RGB]\n",
    "        )(x)\n",
    "\n",
    "    x = layers.ZeroPadding2D(\n",
    "        padding=imagenet_utils.correct_pad(x, 3), name=\"stem_conv_pad\"\n",
    "    )(x)\n",
    "    x = layers.Conv2D(\n",
    "        round_filters(32),\n",
    "        3,\n",
    "        strides=2,\n",
    "        padding=\"valid\",\n",
    "        use_bias=False,\n",
    "        kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        name=\"stem_conv\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=\"stem_bn\")(x)\n",
    "    x = layers.Activation(activation, name=\"stem_activation\")(x)\n",
    "\n",
    "    # Build blocks\n",
    "    blocks_args = copy.deepcopy(blocks_args)\n",
    "\n",
    "    b = 0\n",
    "    blocks = float(sum(round_repeats(args[\"repeats\"]) for args in blocks_args))\n",
    "    for i, args in enumerate(blocks_args):\n",
    "        assert args[\"repeats\"] > 0\n",
    "        # Update block input and output filters based on depth multiplier.\n",
    "        args[\"filters_in\"] = round_filters(args[\"filters_in\"])\n",
    "        args[\"filters_out\"] = round_filters(args[\"filters_out\"])\n",
    "\n",
    "        for j in range(round_repeats(args.pop(\"repeats\"))):\n",
    "            # The first block needs to take care of stride and filter size\n",
    "            # increase.\n",
    "            if j > 0:\n",
    "                args[\"strides\"] = 1\n",
    "                args[\"filters_in\"] = args[\"filters_out\"]\n",
    "            x = block(\n",
    "                x,\n",
    "                activation,\n",
    "                drop_connect_rate * b / blocks,\n",
    "                name=f\"block{i + 1}{chr(j + 97)}_\",\n",
    "                **args,\n",
    "            )\n",
    "            b += 1\n",
    "\n",
    "    # Build top\n",
    "    x = layers.Conv2D(\n",
    "        round_filters(1280),\n",
    "        1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        name=\"top_conv\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=\"top_bn\")(x)\n",
    "    x = layers.Activation(activation, name=\"top_activation\")(x)\n",
    "    if include_top:\n",
    "        x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "        if dropout_rate > 0:\n",
    "            x = layers.Dropout(dropout_rate, name=\"top_dropout\")(x)\n",
    "        imagenet_utils.validate_activation(classifier_activation, weights)\n",
    "        x = layers.Dense(\n",
    "            classes,\n",
    "            activation=classifier_activation,\n",
    "            kernel_initializer=DENSE_KERNEL_INITIALIZER,\n",
    "            name=\"predictions\",\n",
    "        )(x)\n",
    "    else:\n",
    "        if pooling == \"avg\":\n",
    "            x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "        elif pooling == \"max\":\n",
    "            x = layers.GlobalMaxPooling2D(name=\"max_pool\")(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = operation_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Create model.\n",
    "    model = Functional(inputs, x, name=model_name)\n",
    "\n",
    "    # Load weights.\n",
    "    if weights == \"imagenet\":\n",
    "        if include_top:\n",
    "            file_suffix = \".h5\"\n",
    "            file_hash = WEIGHTS_HASHES[model_name[-2:]][0]\n",
    "        else:\n",
    "            file_suffix = \"_notop.h5\"\n",
    "            file_hash = WEIGHTS_HASHES[model_name[-2:]][1]\n",
    "        file_name = model_name + file_suffix\n",
    "        weights_path = file_utils.get_file(\n",
    "            file_name,\n",
    "            BASE_WEIGHTS_PATH + file_name,\n",
    "            cache_subdir=\"models\",\n",
    "            file_hash=file_hash,\n",
    "        )\n",
    "        model.load_weights(weights_path)\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "    return model\n",
    "\n",
    "\n",
    "def block(\n",
    "    inputs,\n",
    "    activation=\"swish\",\n",
    "    drop_rate=0.0,\n",
    "    name=\"\",\n",
    "    filters_in=32,\n",
    "    filters_out=16,\n",
    "    kernel_size=3,\n",
    "    strides=1,\n",
    "    expand_ratio=1,\n",
    "    se_ratio=0.0,\n",
    "    id_skip=True,\n",
    "):\n",
    "    \"\"\"An inverted residual block.\n",
    "\n",
    "    Args:\n",
    "        inputs: input tensor.\n",
    "        activation: activation function.\n",
    "        drop_rate: float between 0 and 1, fraction of the input units to drop.\n",
    "        name: string, block label.\n",
    "        filters_in: integer, the number of input filters.\n",
    "        filters_out: integer, the number of output filters.\n",
    "        kernel_size: integer, the dimension of the convolution window.\n",
    "        strides: integer, the stride of the convolution.\n",
    "        expand_ratio: integer, scaling coefficient for the input filters.\n",
    "        se_ratio: float between 0 and 1, fraction to squeeze the input filters.\n",
    "        id_skip: boolean.\n",
    "\n",
    "    Returns:\n",
    "        output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3 if backend.image_data_format() == \"channels_last\" else 1\n",
    "\n",
    "    # Expansion phase\n",
    "    filters = filters_in * expand_ratio\n",
    "    if expand_ratio != 1:\n",
    "        x = layers.Conv2D(\n",
    "            filters,\n",
    "            1,\n",
    "            padding=\"same\",\n",
    "            use_bias=False,\n",
    "            kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "            name=name + \"expand_conv\",\n",
    "        )(inputs)\n",
    "        x = layers.BatchNormalization(axis=bn_axis, name=name + \"expand_bn\")(x)\n",
    "        x = layers.Activation(activation, name=name + \"expand_activation\")(x)\n",
    "    else:\n",
    "        x = inputs\n",
    "\n",
    "    # Depthwise Convolution\n",
    "    if strides == 2:\n",
    "        x = layers.ZeroPadding2D(\n",
    "            padding=imagenet_utils.correct_pad(x, kernel_size),\n",
    "            name=name + \"dwconv_pad\",\n",
    "        )(x)\n",
    "        conv_pad = \"valid\"\n",
    "    else:\n",
    "        conv_pad = \"same\"\n",
    "    x = layers.DepthwiseConv2D(\n",
    "        kernel_size,\n",
    "        strides=strides,\n",
    "        padding=conv_pad,\n",
    "        use_bias=False,\n",
    "        depthwise_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        name=name + \"dwconv\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=name + \"bn\")(x)\n",
    "    x = layers.Activation(activation, name=name + \"activation\")(x)\n",
    "\n",
    "    # Squeeze and Excitation phase\n",
    "    if 0 < se_ratio <= 1:\n",
    "        filters_se = max(1, int(filters_in * se_ratio))\n",
    "        se = layers.GlobalAveragePooling2D(name=name + \"se_squeeze\")(x)\n",
    "        if bn_axis == 1:\n",
    "            se_shape = (filters, 1, 1)\n",
    "        else:\n",
    "            se_shape = (1, 1, filters)\n",
    "        se = layers.Reshape(se_shape, name=name + \"se_reshape\")(se)\n",
    "        se = layers.Conv2D(\n",
    "            filters_se,\n",
    "            1,\n",
    "            padding=\"same\",\n",
    "            activation=activation,\n",
    "            kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "            name=name + \"se_reduce\",\n",
    "        )(se)\n",
    "        se = layers.Conv2D(\n",
    "            filters,\n",
    "            1,\n",
    "            padding=\"same\",\n",
    "            activation=\"sigmoid\",\n",
    "            kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "            name=name + \"se_expand\",\n",
    "        )(se)\n",
    "        x = layers.multiply([x, se], name=name + \"se_excite\")\n",
    "\n",
    "    # Output phase\n",
    "    x = layers.Conv2D(\n",
    "        filters_out,\n",
    "        1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        name=name + \"project_conv\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=name + \"project_bn\")(x)\n",
    "    if id_skip and strides == 1 and filters_in == filters_out:\n",
    "        if drop_rate > 0:\n",
    "            x = layers.Dropout(\n",
    "                drop_rate, noise_shape=(None, 1, 1, 1), name=name + \"drop\"\n",
    "            )(x)\n",
    "        x = layers.add([x, inputs], name=name + \"add\")\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\n",
    "    [\n",
    "        \"keras.applications.efficientnet.EfficientNetB0\",\n",
    "        \"keras.applications.EfficientNetB0\",\n",
    "    ]\n",
    ")\n",
    "def EfficientNetB0(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs,\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.0,\n",
    "        1.0,\n",
    "        224,\n",
    "        0.2,\n",
    "        model_name=\"efficientnetb0\",\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        classes=classes,\n",
    "        classifier_activation=classifier_activation,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "@keras_export(\n",
    "    [\n",
    "        \"keras.applications.efficientnet.EfficientNetB1\",\n",
    "        \"keras.applications.EfficientNetB1\",\n",
    "    ]\n",
    ")\n",
    "def EfficientNetB1(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs,\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.0,\n",
    "        1.1,\n",
    "        240,\n",
    "        0.2,\n",
    "        model_name=\"efficientnetb1\",\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        classes=classes,\n",
    "        classifier_activation=classifier_activation,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "@keras_export(\n",
    "    [\n",
    "        \"keras.applications.efficientnet.EfficientNetB2\",\n",
    "        \"keras.applications.EfficientNetB2\",\n",
    "    ]\n",
    ")\n",
    "def EfficientNetB2(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs,\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.1,\n",
    "        1.2,\n",
    "        260,\n",
    "        0.3,\n",
    "        model_name=\"efficientnetb2\",\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        classes=classes,\n",
    "        classifier_activation=classifier_activation,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "@keras_export(\n",
    "    [\n",
    "        \"keras.applications.efficientnet.EfficientNetB3\",\n",
    "        \"keras.applications.EfficientNetB3\",\n",
    "    ]\n",
    ")\n",
    "def EfficientNetB3(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs,\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.2,\n",
    "        1.4,\n",
    "        300,\n",
    "        0.3,\n",
    "        model_name=\"efficientnetb3\",\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        classes=classes,\n",
    "        classifier_activation=classifier_activation,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "@keras_export(\n",
    "    [\n",
    "        \"keras.applications.efficientnet.EfficientNetB4\",\n",
    "        \"keras.applications.EfficientNetB4\",\n",
    "    ]\n",
    ")\n",
    "def EfficientNetB4(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs,\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.4,\n",
    "        1.8,\n",
    "        380,\n",
    "        0.4,\n",
    "        model_name=\"efficientnetb4\",\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        classes=classes,\n",
    "        classifier_activation=classifier_activation,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "@keras_export(\n",
    "    [\n",
    "        \"keras.applications.efficientnet.EfficientNetB5\",\n",
    "        \"keras.applications.EfficientNetB5\",\n",
    "    ]\n",
    ")\n",
    "def EfficientNetB5(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs,\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.6,\n",
    "        2.2,\n",
    "        456,\n",
    "        0.4,\n",
    "        model_name=\"efficientnetb5\",\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        classes=classes,\n",
    "        classifier_activation=classifier_activation,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "@keras_export(\n",
    "    [\n",
    "        \"keras.applications.efficientnet.EfficientNetB6\",\n",
    "        \"keras.applications.EfficientNetB6\",\n",
    "    ]\n",
    ")\n",
    "def EfficientNetB6(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs,\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.8,\n",
    "        2.6,\n",
    "        528,\n",
    "        0.5,\n",
    "        model_name=\"efficientnetb6\",\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        classes=classes,\n",
    "        classifier_activation=classifier_activation,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "@keras_export(\n",
    "    [\n",
    "        \"keras.applications.efficientnet.EfficientNetB7\",\n",
    "        \"keras.applications.EfficientNetB7\",\n",
    "    ]\n",
    ")\n",
    "def EfficientNetB7(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs,\n",
    "):\n",
    "    return EfficientNet(\n",
    "        2.0,\n",
    "        3.1,\n",
    "        600,\n",
    "        0.5,\n",
    "        model_name=\"efficientnetb7\",\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=input_shape,\n",
    "        pooling=pooling,\n",
    "        classes=classes,\n",
    "        classifier_activation=classifier_activation,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "EfficientNetB0.__doc__ = BASE_DOCSTRING.format(name=\"EfficientNetB0\")\n",
    "EfficientNetB1.__doc__ = BASE_DOCSTRING.format(name=\"EfficientNetB1\")\n",
    "EfficientNetB2.__doc__ = BASE_DOCSTRING.format(name=\"EfficientNetB2\")\n",
    "EfficientNetB3.__doc__ = BASE_DOCSTRING.format(name=\"EfficientNetB3\")\n",
    "EfficientNetB4.__doc__ = BASE_DOCSTRING.format(name=\"EfficientNetB4\")\n",
    "EfficientNetB5.__doc__ = BASE_DOCSTRING.format(name=\"EfficientNetB5\")\n",
    "EfficientNetB6.__doc__ = BASE_DOCSTRING.format(name=\"EfficientNetB6\")\n",
    "EfficientNetB7.__doc__ = BASE_DOCSTRING.format(name=\"EfficientNetB7\")\n",
    "\n",
    "\n",
    "@keras_export(\"keras.applications.efficientnet.preprocess_input\")\n",
    "def preprocess_input(x, data_format=None):\n",
    "    \"\"\"A placeholder method for backward compatibility.\n",
    "\n",
    "    The preprocessing logic has been included in the efficientnet model\n",
    "    implementation. Users are no longer required to call this method to\n",
    "    normalize the input data. This method does nothing and only kept as a\n",
    "    placeholder to align the API surface between old and new version of model.\n",
    "\n",
    "    Args:\n",
    "        x: A floating point `numpy.array` or a tensor.\n",
    "        data_format: Optional data format of the image tensor/array. `None`\n",
    "            means the global setting `keras.backend.image_data_format()`\n",
    "            is used (unless you changed it, it uses `\"channels_last\"`).\n",
    "            Defaults to `None`.\n",
    "\n",
    "    Returns:\n",
    "        Unchanged `numpy.array` or tensor.\n",
    "    \"\"\"\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\"keras.applications.efficientnet.decode_predictions\")\n",
    "def decode_predictions(preds, top=5):\n",
    "    return imagenet_utils.decode_predictions(preds, top=top)\n",
    "\n",
    "\n",
    "decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b9789e-40f4-47d0-b79c-0e4ebf09d7f2",
   "metadata": {},
   "source": [
    "## Define Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b1b0aa-c159-48d2-a10b-c9a0bd53e0fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def augment_and_resize_dataset(base_path, img_size, batch_size, preprocess_input_func=None):\n",
    "    train_path = os.path.join(base_path, 'train')\n",
    "    validation_path = os.path.join(base_path, 'val')\n",
    "    test_path = os.path.join(base_path, 'test')\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input_func,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    # Untuk data validation dan test, hanya preprocessing\n",
    "    validation_test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_func)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    validation_generator = validation_test_datagen.flow_from_directory(\n",
    "        validation_path,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    test_generator = validation_test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_generator, validation_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf6b557-6c2e-4266-a8c0-3abb0110b86a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Fungsi untuk melatih model dan menampilkan grafik serta menyimpannya\n",
    "def train_and_plot(model, model_name, train_generator, validation_generator, test_generator, epochs):\n",
    "    # Callback untuk menghentikan pelatihan jika tidak ada perbaikan setelah beberapa epoch\n",
    "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Menghitung waktu mulai pelatihan\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Melatih model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=validation_generator,\n",
    "        epochs=epochs,\n",
    "        callbacks=[early_stopping_callback]\n",
    "    )\n",
    "    \n",
    "    # Menghitung waktu selesai pelatihan\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Menghitung durasi pelatihan\n",
    "    training_duration = end_time - start_time  # dalam detik\n",
    "\n",
    "    # Plotting hasil akurasi\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot training & validation accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'{model_name} Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'{model_name} Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # Tampilkan plot\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluasi model pada data test\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Prediksi pada data test\n",
    "    y_pred = model.predict(test_generator)\n",
    "\n",
    "    # Mengambil index dari prediksi (kelas dengan probabilitas tertinggi)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Mengambil label sebenarnya dari generator\n",
    "    y_true = test_generator.classes\n",
    "\n",
    "    # Membuat confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    class_names = list(test_generator.class_indices.keys())\n",
    "\n",
    "    # Menampilkan classification report\n",
    "    print(\"Classification Report:\\n\", classification_report(y_true, y_pred_classes, target_names=class_names))\n",
    "\n",
    "    # Plot confusion matrix sebagai heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    # Tampilkan confusion matrix\n",
    "    plt.show()\n",
    "\n",
    "    return history, test_loss, test_accuracy, training_duration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ee1eb-5784-4520-9abd-c73b1a420005",
   "metadata": {},
   "source": [
    "## Training menggunakan EfficientNet Modified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78e126d-bcc1-44f6-b190-7f3f98ced462",
   "metadata": {},
   "source": [
    "### B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820b5dc4-f773-412b-b0e7-e25b4aeacbee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = EfficientNetB0(input_shape=(224, 224, 3), include_top=False, weights=None)\n",
    "model.trainable = True\n",
    "\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "\n",
    "x = model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "outputs = Dense(3, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49685a4e-6c3e-4dc5-ad72-1f497073b2b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator, validation_generator, test_generator = augment_and_resize_dataset(\n",
    "    \"data/split_train_test_dataset_campuran\",\n",
    "    img_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    preprocess_input_func = efficientnet_preprocess\n",
    ")\n",
    "\n",
    "history_EN_B0, test_loss, test_acc, training_duration = train_and_plot(model, \"EfficientNetB0_Custom\", train_generator, validation_generator, test_generator, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d39f9e8-219f-41f3-af46-0286a3694c1f",
   "metadata": {},
   "source": [
    "### B7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3528a16-4149-40a8-9225-3ca0de886ebf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = EfficientNetB7(input_shape=(600, 600, 3), include_top=False, weights=None)\n",
    "model.trainable = True\n",
    "\n",
    "inputs = Input(shape=(600, 600, 3))\n",
    "\n",
    "x = model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "outputs = Dense(3, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627875ef-ab39-451f-971a-aac021fd70bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator, validation_generator, test_generator = augment_and_resize_dataset(\n",
    "    \"data/split_train_test_dataset_campuran\",\n",
    "    img_size=(600, 600),\n",
    "    batch_size=16,\n",
    "    preprocess_input_func = efficientnet_preprocess\n",
    ")\n",
    "\n",
    "history_EN_B7, test_loss, test_acc, training_duration = train_and_plot(model, \"EfficientNetB7_Custom\", train_generator, validation_generator, test_generator, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced06ad7-7ae3-4610-ba18-1fecf236056e",
   "metadata": {},
   "source": [
    "# Test KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f8e975-4404-4434-a8db-9bcf506b02bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator, test_generator = augment_and_resize_dataset(\n",
    "    \"data/split_train_test_dataset_campuran\",\n",
    "    img_size=(600, 600),\n",
    "    batch_size=16,\n",
    "    preprocess_input_func = efficientnet_preprocess\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2baa849-9af9-4911-8e32-09bbf2af881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ekstrak seluruh data dan label dari generator\n",
    "def extract_images_labels(generator):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _ in range(len(generator)):  # Iterasi untuk setiap batch\n",
    "        img_batch, label_batch = next(generator)\n",
    "        images.append(img_batch)\n",
    "        labels.append(label_batch)\n",
    "    \n",
    "    # Menggabungkan list menjadi array numpy\n",
    "    images = np.concatenate(images)\n",
    "    labels = np.concatenate(labels)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# Ekstrak data dari train_generator\n",
    "train_images, train_labels = extract_images_labels(train_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93afaea-4ddf-441e-9d22-e8ec93c72e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have train data and labels loaded, e.g., train_images, train_labels\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "# Inisialisasi variabel untuk menyimpan hasil\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "# K-Fold Cross Validation model evaluation\n",
    "for train_index, val_index in kfold.split(train_images, train_labels):\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Split data into training and validation sets for the current fold\n",
    "    x_train_fold = train_images[train_index]\n",
    "    y_train_fold = train_labels[train_index]\n",
    "    x_val_fold = train_images[val_index]\n",
    "    y_val_fold = train_labels[val_index]\n",
    "\n",
    "    # Create model for this fold\n",
    "    model = EfficientNetB1(input_shape=(600, 600, 3), include_top=False, weights=None)\n",
    "    model.trainable = True\n",
    "    \n",
    "    inputs = Input(shape=(600, 600, 3))\n",
    "    x = model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    outputs = Dense(3, activation='softmax')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model for this fold\n",
    "    history = model.fit(x_train_fold, y_train_fold,\n",
    "                        epochs=50,\n",
    "                        batch_size=16,\n",
    "                        validation_data=(x_val_fold, y_val_fold))\n",
    "\n",
    "    # Mengevaluasi model di data validasi\n",
    "    scores = model.evaluate(x_val_fold, y_val_fold, verbose=0)\n",
    "    print(f\"Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%\")\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Menampilkan hasil akhir dari cross-validation\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
