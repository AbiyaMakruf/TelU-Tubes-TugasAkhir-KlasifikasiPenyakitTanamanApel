{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d75b4748-50a3-4c4b-afe0-333b7b1cd326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras import mixed_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff9a3903-4c87-4f10-978d-deb91d582406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 2s/step - accuracy: 0.3355 - loss: 1.7791 - val_accuracy: 0.3420 - val_loss: 1.0981\n",
      "Epoch 2/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 144ms/step - accuracy: 0.3603 - loss: 1.8064 - val_accuracy: 0.3420 - val_loss: 1.1706\n",
      "Epoch 3/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 141ms/step - accuracy: 0.3718 - loss: 1.7116 - val_accuracy: 0.3477 - val_loss: 1.6247\n",
      "Epoch 4/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 142ms/step - accuracy: 0.3540 - loss: 1.9605 - val_accuracy: 0.3420 - val_loss: 1.0961\n",
      "Epoch 5/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 152ms/step - accuracy: 0.3447 - loss: 1.9345 - val_accuracy: 0.3592 - val_loss: 1.0964\n",
      "Epoch 6/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 154ms/step - accuracy: 0.3458 - loss: 1.8362 - val_accuracy: 0.3678 - val_loss: 5.3090\n",
      "Epoch 7/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 148ms/step - accuracy: 0.3382 - loss: 1.9306 - val_accuracy: 0.3391 - val_loss: nan\n",
      "Epoch 8/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - accuracy: 0.3506 - loss: 1.9354 - val_accuracy: 0.3649 - val_loss: 1.2176\n",
      "Epoch 9/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 151ms/step - accuracy: 0.3413 - loss: 1.9345 - val_accuracy: 0.2874 - val_loss: nan\n",
      "Epoch 10/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 149ms/step - accuracy: 0.3262 - loss: 2.1265 - val_accuracy: 0.3534 - val_loss: 3.2790\n",
      "Epoch 11/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 148ms/step - accuracy: 0.3680 - loss: 1.6486 - val_accuracy: 0.3621 - val_loss: 1.8682\n",
      "Epoch 12/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 143ms/step - accuracy: 0.3489 - loss: 1.7199 - val_accuracy: 0.3678 - val_loss: 1.4089\n",
      "Epoch 13/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 153ms/step - accuracy: 0.3542 - loss: 1.8639 - val_accuracy: 0.3621 - val_loss: 1.4159\n",
      "Epoch 14/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 146ms/step - accuracy: 0.3588 - loss: 1.7542 - val_accuracy: 0.3621 - val_loss: 1.3912\n",
      "Epoch 15/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 146ms/step - accuracy: 0.3710 - loss: 1.6992 - val_accuracy: 0.3592 - val_loss: 2.3962\n",
      "Epoch 16/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 149ms/step - accuracy: 0.3437 - loss: 1.6863 - val_accuracy: 0.3764 - val_loss: 2.2625\n",
      "Epoch 17/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - accuracy: 0.3657 - loss: 1.7197 - val_accuracy: 0.3851 - val_loss: 1.8160\n",
      "Epoch 18/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 148ms/step - accuracy: 0.3523 - loss: 1.7024 - val_accuracy: 0.3764 - val_loss: 1.5632\n",
      "Epoch 19/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 151ms/step - accuracy: 0.3655 - loss: 1.6408 - val_accuracy: 0.3764 - val_loss: 1.5199\n",
      "Epoch 20/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 151ms/step - accuracy: 0.3476 - loss: 1.7844 - val_accuracy: 0.3707 - val_loss: 3.1290\n",
      "Epoch 21/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 151ms/step - accuracy: 0.3523 - loss: 1.7444 - val_accuracy: 0.4339 - val_loss: 2.6130\n",
      "Epoch 22/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - accuracy: 0.3411 - loss: 1.8971 - val_accuracy: 0.3908 - val_loss: 4.0502\n",
      "Epoch 23/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 141ms/step - accuracy: 0.3422 - loss: 1.7824 - val_accuracy: 0.3592 - val_loss: 1.0960\n",
      "Epoch 24/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 146ms/step - accuracy: 0.3560 - loss: 1.7157 - val_accuracy: 0.3621 - val_loss: 1.6406\n",
      "Epoch 25/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 145ms/step - accuracy: 0.3505 - loss: 1.5881 - val_accuracy: 0.3592 - val_loss: 1.3851\n",
      "Epoch 26/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 147ms/step - accuracy: 0.2996 - loss: 1.8946 - val_accuracy: 0.3448 - val_loss: 1.6563\n",
      "Epoch 27/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 149ms/step - accuracy: 0.3454 - loss: 1.8858 - val_accuracy: 0.3506 - val_loss: 1.6466\n",
      "Epoch 28/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 146ms/step - accuracy: 0.3739 - loss: 1.6641 - val_accuracy: 0.3822 - val_loss: 1.5969\n",
      "Epoch 29/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 151ms/step - accuracy: 0.3615 - loss: 1.7779 - val_accuracy: 0.3477 - val_loss: 1.5688\n",
      "Epoch 30/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - accuracy: 0.3547 - loss: 1.7045 - val_accuracy: 0.3420 - val_loss: 1.6609\n",
      "Epoch 31/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 152ms/step - accuracy: 0.3679 - loss: 1.8853 - val_accuracy: 0.3448 - val_loss: 1.6552\n",
      "Epoch 32/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 151ms/step - accuracy: 0.3441 - loss: 1.8516 - val_accuracy: 0.3477 - val_loss: 1.6111\n",
      "Epoch 33/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 149ms/step - accuracy: 0.3618 - loss: 1.7682 - val_accuracy: 0.3477 - val_loss: 1.6118\n",
      "Epoch 34/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - accuracy: 0.3353 - loss: 1.8370 - val_accuracy: 0.3477 - val_loss: 1.6117\n",
      "Epoch 35/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 148ms/step - accuracy: 0.3413 - loss: 1.8633 - val_accuracy: 0.3477 - val_loss: 1.6117\n",
      "Epoch 36/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - accuracy: 0.3567 - loss: 1.7767 - val_accuracy: 0.3477 - val_loss: 1.6116\n",
      "Epoch 37/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - accuracy: 0.3526 - loss: 1.8956 - val_accuracy: 0.3420 - val_loss: 1.6890\n",
      "Epoch 38/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 151ms/step - accuracy: 0.3661 - loss: 1.6826 - val_accuracy: 0.3621 - val_loss: 1.1381\n",
      "Epoch 39/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - accuracy: 0.3628 - loss: 1.8509 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 40/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 144ms/step - accuracy: 0.3574 - loss: 1.6373 - val_accuracy: 0.2931 - val_loss: nan\n",
      "Epoch 41/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 144ms/step - accuracy: 0.3548 - loss: 1.8184 - val_accuracy: 0.2902 - val_loss: nan\n",
      "Epoch 42/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 147ms/step - accuracy: 0.3537 - loss: 1.7297 - val_accuracy: 0.3563 - val_loss: nan\n",
      "Epoch 43/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 148ms/step - accuracy: 0.3591 - loss: 1.8056 - val_accuracy: 0.3592 - val_loss: 1.7057\n",
      "Epoch 44/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - accuracy: 0.3543 - loss: 1.7271 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 45/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 149ms/step - accuracy: 0.3511 - loss: 1.8035 - val_accuracy: 0.3592 - val_loss: 2.1825\n",
      "Epoch 46/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 148ms/step - accuracy: 0.3479 - loss: 1.7601 - val_accuracy: 0.3592 - val_loss: 1.2282\n",
      "Epoch 47/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 149ms/step - accuracy: 0.3732 - loss: 1.7342 - val_accuracy: 0.3247 - val_loss: nan\n",
      "Epoch 48/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 148ms/step - accuracy: 0.3764 - loss: 2.5137 - val_accuracy: 0.3621 - val_loss: 1.7660\n",
      "Epoch 49/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - accuracy: 0.3254 - loss: 1.9712 - val_accuracy: 0.3563 - val_loss: nan\n",
      "Epoch 50/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 149ms/step - accuracy: 0.3788 - loss: 1.7713 - val_accuracy: 0.3592 - val_loss: 1.8901\n",
      "Epoch 51/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 151ms/step - accuracy: 0.3869 - loss: 1.7019 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 52/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 151ms/step - accuracy: 0.3721 - loss: 1.9016 - val_accuracy: 0.3592 - val_loss: 1.1389\n",
      "Epoch 53/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 160ms/step - accuracy: 0.3589 - loss: 1.7712 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 54/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 163ms/step - accuracy: 0.3259 - loss: 1.9494 - val_accuracy: 0.3592 - val_loss: 1.0925\n",
      "Epoch 55/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 161ms/step - accuracy: 0.3679 - loss: 1.7773 - val_accuracy: 0.3563 - val_loss: 1.3935\n",
      "Epoch 56/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 162ms/step - accuracy: 0.3488 - loss: 1.2648 - val_accuracy: 0.3477 - val_loss: 1.4212\n",
      "Epoch 57/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 162ms/step - accuracy: 0.3275 - loss: 1.1327 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 58/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 159ms/step - accuracy: 0.3538 - loss: 1.0986 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 59/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 163ms/step - accuracy: 0.3678 - loss: 1.1016 - val_accuracy: 0.3506 - val_loss: 1.0964\n",
      "Epoch 60/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 159ms/step - accuracy: 0.3480 - loss: 1.0977 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 61/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 158ms/step - accuracy: 0.3665 - loss: 1.0957 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 62/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 160ms/step - accuracy: 0.3701 - loss: 1.0967 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 63/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 160ms/step - accuracy: 0.3703 - loss: 1.0969 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 64/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 157ms/step - accuracy: 0.3553 - loss: 1.0980 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 65/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 145ms/step - accuracy: 0.3755 - loss: 1.0926 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 66/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 143ms/step - accuracy: 0.3564 - loss: 1.0974 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 67/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 162ms/step - accuracy: 0.3573 - loss: 1.0962 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 68/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 160ms/step - accuracy: 0.3733 - loss: 1.0949 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 69/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 165ms/step - accuracy: 0.3330 - loss: 1.0977 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 70/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 157ms/step - accuracy: 0.3496 - loss: 1.0996 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 71/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 158ms/step - accuracy: 0.3589 - loss: 1.0957 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 72/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 145ms/step - accuracy: 0.3679 - loss: 1.0935 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 73/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 159ms/step - accuracy: 0.3569 - loss: 1.0959 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 74/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 164ms/step - accuracy: 0.3515 - loss: 1.0929 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 75/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 161ms/step - accuracy: 0.3588 - loss: 1.0966 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 76/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 159ms/step - accuracy: 0.3475 - loss: 1.0961 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 77/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 160ms/step - accuracy: 0.3570 - loss: 1.0957 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 78/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 162ms/step - accuracy: 0.3611 - loss: 1.0954 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 79/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 162ms/step - accuracy: 0.3589 - loss: 1.0948 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 80/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 162ms/step - accuracy: 0.3714 - loss: 1.0939 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 81/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 161ms/step - accuracy: 0.3535 - loss: 1.0949 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 82/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 161ms/step - accuracy: 0.3559 - loss: 1.0955 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 83/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 157ms/step - accuracy: 0.3528 - loss: 1.0962 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 84/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 154ms/step - accuracy: 0.3730 - loss: 1.0933 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 85/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - accuracy: 0.3622 - loss: 1.0941 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 86/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 154ms/step - accuracy: 0.3773 - loss: 1.0931 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 87/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 147ms/step - accuracy: 0.3860 - loss: 1.0911 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 88/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - accuracy: 0.3691 - loss: 1.0977 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 89/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 160ms/step - accuracy: 0.3564 - loss: 1.0947 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 90/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 160ms/step - accuracy: 0.3498 - loss: 1.0981 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 91/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 159ms/step - accuracy: 0.3776 - loss: 1.0945 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 92/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 154ms/step - accuracy: 0.3441 - loss: 1.0973 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 93/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 160ms/step - accuracy: 0.3583 - loss: 1.0960 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 94/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 159ms/step - accuracy: 0.3528 - loss: 1.0971 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 95/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 157ms/step - accuracy: 0.3619 - loss: 1.0940 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 96/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 151ms/step - accuracy: 0.3569 - loss: 1.0969 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 97/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 161ms/step - accuracy: 0.3651 - loss: 1.0944 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 98/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 152ms/step - accuracy: 0.3657 - loss: 1.0964 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 99/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 160ms/step - accuracy: 0.3801 - loss: 1.0937 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 100/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 149ms/step - accuracy: 0.3617 - loss: 1.0952 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Model training selesai dan disimpan sebagai efficientnetb7_apple_leaf_disease.h5\n"
     ]
    }
   ],
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Fungsi untuk memuat dan preprocess citra\n",
    "def load_images_and_labels(image_dir, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(image_dir)\n",
    "    class_dict = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(image_dir, class_name)\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Gagal memuat gambar: {image_path}\")\n",
    "                continue\n",
    "            image = cv2.resize(image, image_size)\n",
    "            images.append(image)\n",
    "            labels.append(class_dict[class_name])\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, class_dict\n",
    "\n",
    "# Path dataset\n",
    "base_dir = 'data/split_train_test_dataset_campuran'\n",
    "\n",
    "# Load dataset train, val, test\n",
    "image_size = (224, 224)  # Ukuran citra input yang sesuai untuk EfficientNetB7\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "X_train, y_train, class_dict = load_images_and_labels(train_dir, image_size)\n",
    "X_val, y_val, _ = load_images_and_labels(val_dir, image_size)\n",
    "X_test, y_test, _ = load_images_and_labels(test_dir, image_size)\n",
    "\n",
    "# Normalisasi citra\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Data augmentation untuk training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "# Preprocess input sesuai dengan EfficientNetB7\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=16)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=16)\n",
    "\n",
    "# Load model EfficientNet B7 tanpa pre-trained weights\n",
    "base_model = EfficientNetB7(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Menambahkan layer klasifikasi\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
    "predictions = Dense(len(class_dict), activation='softmax')(x)  # Output layer\n",
    "\n",
    "# Membangun model lengkap\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training model\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=100)\n",
    "\n",
    "# Save model\n",
    "model.save('efficientnetb7_apple_leaf_disease.keras')\n",
    "\n",
    "print(\"Model training selesai dan disimpan sebagai efficientnetb7_apple_leaf_disease.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772d6dd1-e00b-44b8-aba5-a4df3f43a100",
   "metadata": {},
   "source": [
    "# B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e79f6d48-2c28-4b9a-a44a-9f951c025fa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 869ms/step - accuracy: 0.3567 - loss: 1.8253 - val_accuracy: 0.3420 - val_loss: 1.2031\n",
      "Epoch 2/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.3840 - loss: 1.1409 - val_accuracy: 0.3420 - val_loss: 1.2412\n",
      "Epoch 3/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 134ms/step - accuracy: 0.4140 - loss: 1.0853 - val_accuracy: 0.3420 - val_loss: 1.1764\n",
      "Epoch 4/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 134ms/step - accuracy: 0.5008 - loss: 1.0291 - val_accuracy: 0.3420 - val_loss: 1.7340\n",
      "Epoch 5/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - accuracy: 0.5519 - loss: 0.9055 - val_accuracy: 0.3420 - val_loss: 2.6685\n",
      "Epoch 6/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step - accuracy: 0.6450 - loss: 0.7563 - val_accuracy: 0.3420 - val_loss: 1.5889\n",
      "Epoch 7/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 127ms/step - accuracy: 0.6856 - loss: 0.6893 - val_accuracy: 0.3420 - val_loss: 6.2133\n",
      "Epoch 8/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 133ms/step - accuracy: 0.7304 - loss: 0.5775 - val_accuracy: 0.3621 - val_loss: 5.6678\n",
      "Epoch 9/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.7139 - loss: 0.5599 - val_accuracy: 0.6609 - val_loss: 0.9647\n",
      "Epoch 10/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 127ms/step - accuracy: 0.7547 - loss: 0.5503 - val_accuracy: 0.7126 - val_loss: 0.5925\n",
      "Epoch 11/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 127ms/step - accuracy: 0.7600 - loss: 0.5508 - val_accuracy: 0.7500 - val_loss: 1.5060\n",
      "Epoch 12/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 139ms/step - accuracy: 0.7600 - loss: 0.5330 - val_accuracy: 0.4540 - val_loss: 4.2026\n",
      "Epoch 13/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 139ms/step - accuracy: 0.7552 - loss: 0.5199 - val_accuracy: 0.7960 - val_loss: 0.5508\n",
      "Epoch 14/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step - accuracy: 0.8046 - loss: 0.4591 - val_accuracy: 0.6638 - val_loss: 1.2134\n",
      "Epoch 15/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 130ms/step - accuracy: 0.8214 - loss: 0.4280 - val_accuracy: 0.7787 - val_loss: 0.4850\n",
      "Epoch 16/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step - accuracy: 0.8495 - loss: 0.3784 - val_accuracy: 0.8534 - val_loss: 0.4599\n",
      "Epoch 17/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - accuracy: 0.8751 - loss: 0.3271 - val_accuracy: 0.7356 - val_loss: 0.9086\n",
      "Epoch 18/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 133ms/step - accuracy: 0.8731 - loss: 0.3259 - val_accuracy: 0.8908 - val_loss: 0.2656\n",
      "Epoch 19/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - accuracy: 0.8989 - loss: 0.2395 - val_accuracy: 0.8736 - val_loss: 0.4100\n",
      "Epoch 20/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 140ms/step - accuracy: 0.9263 - loss: 0.2421 - val_accuracy: 0.8649 - val_loss: 0.3934\n",
      "Epoch 21/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 0.9124 - loss: 0.2320 - val_accuracy: 0.9454 - val_loss: 0.1634\n",
      "Epoch 22/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step - accuracy: 0.9258 - loss: 0.1958 - val_accuracy: 0.9167 - val_loss: 0.1834\n",
      "Epoch 23/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 135ms/step - accuracy: 0.9057 - loss: 0.2417 - val_accuracy: 0.9310 - val_loss: 0.1333\n",
      "Epoch 24/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 137ms/step - accuracy: 0.9370 - loss: 0.1721 - val_accuracy: 0.9483 - val_loss: 0.1472\n",
      "Epoch 25/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 143ms/step - accuracy: 0.9265 - loss: 0.2003 - val_accuracy: 0.8879 - val_loss: 0.3549\n",
      "Epoch 26/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 137ms/step - accuracy: 0.9425 - loss: 0.1529 - val_accuracy: 0.9425 - val_loss: 0.1488\n",
      "Epoch 27/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step - accuracy: 0.9276 - loss: 0.1998 - val_accuracy: 0.9598 - val_loss: 0.1135\n",
      "Epoch 28/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step - accuracy: 0.9305 - loss: 0.2160 - val_accuracy: 0.6839 - val_loss: 0.7678\n",
      "Epoch 29/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - accuracy: 0.8228 - loss: 0.4468 - val_accuracy: 0.9368 - val_loss: 0.1796\n",
      "Epoch 30/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 134ms/step - accuracy: 0.9484 - loss: 0.1650 - val_accuracy: 0.9109 - val_loss: 0.2635\n",
      "Epoch 31/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 133ms/step - accuracy: 0.9544 - loss: 0.1411 - val_accuracy: 0.9368 - val_loss: 0.1954\n",
      "Epoch 32/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.9628 - loss: 0.1091 - val_accuracy: 0.9511 - val_loss: 0.1385\n",
      "Epoch 33/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.9554 - loss: 0.1260 - val_accuracy: 0.9684 - val_loss: 0.1075\n",
      "Epoch 34/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.9553 - loss: 0.1419 - val_accuracy: 0.9655 - val_loss: 0.0950\n",
      "Epoch 35/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step - accuracy: 0.9532 - loss: 0.1396 - val_accuracy: 0.9713 - val_loss: 0.0882\n",
      "Epoch 36/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.9631 - loss: 0.1187 - val_accuracy: 0.9569 - val_loss: 0.1518\n",
      "Epoch 37/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.9453 - loss: 0.1555 - val_accuracy: 0.9655 - val_loss: 0.1091\n",
      "Epoch 38/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - accuracy: 0.9664 - loss: 0.1021 - val_accuracy: 0.9598 - val_loss: 0.1104\n",
      "Epoch 39/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 134ms/step - accuracy: 0.9635 - loss: 0.1535 - val_accuracy: 0.9569 - val_loss: 0.1156\n",
      "Epoch 40/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 137ms/step - accuracy: 0.9537 - loss: 0.1411 - val_accuracy: 0.9626 - val_loss: 0.1348\n",
      "Epoch 41/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - accuracy: 0.9587 - loss: 0.1428 - val_accuracy: 0.9483 - val_loss: 0.1440\n",
      "Epoch 42/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - accuracy: 0.9535 - loss: 0.1514 - val_accuracy: 0.9195 - val_loss: 0.2428\n",
      "Epoch 43/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 135ms/step - accuracy: 0.9712 - loss: 0.0986 - val_accuracy: 0.4885 - val_loss: 6.6458\n",
      "Epoch 44/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - accuracy: 0.9530 - loss: 0.1808 - val_accuracy: 0.9626 - val_loss: 0.1325\n",
      "Epoch 45/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 136ms/step - accuracy: 0.9687 - loss: 0.1068 - val_accuracy: 0.9483 - val_loss: 0.1582\n",
      "Epoch 46/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 137ms/step - accuracy: 0.9678 - loss: 0.1088 - val_accuracy: 0.9540 - val_loss: 0.1473\n",
      "Epoch 47/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - accuracy: 0.9607 - loss: 0.1042 - val_accuracy: 0.9569 - val_loss: 0.1359\n",
      "Epoch 48/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - accuracy: 0.9633 - loss: 0.1031 - val_accuracy: 0.9770 - val_loss: 0.0755\n",
      "Epoch 49/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 137ms/step - accuracy: 0.9854 - loss: 0.0506 - val_accuracy: 0.9598 - val_loss: 0.1196\n",
      "Epoch 50/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - accuracy: 0.9689 - loss: 0.1076 - val_accuracy: 0.9425 - val_loss: 0.2022\n",
      "Epoch 51/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - accuracy: 0.9679 - loss: 0.1172 - val_accuracy: 0.9598 - val_loss: 0.1146\n",
      "Epoch 52/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 135ms/step - accuracy: 0.9675 - loss: 0.0884 - val_accuracy: 0.9540 - val_loss: 0.1295\n",
      "Epoch 53/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - accuracy: 0.9644 - loss: 0.1246 - val_accuracy: 0.8448 - val_loss: 0.5340\n",
      "Epoch 54/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.9661 - loss: 0.0998 - val_accuracy: 0.9828 - val_loss: 0.0624\n",
      "Epoch 55/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.9664 - loss: 0.1131 - val_accuracy: 0.9684 - val_loss: 0.1237\n",
      "Epoch 56/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.9604 - loss: 0.1403 - val_accuracy: 0.9626 - val_loss: 0.1156\n",
      "Epoch 57/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 133ms/step - accuracy: 0.9746 - loss: 0.0757 - val_accuracy: 0.9655 - val_loss: 0.1088\n",
      "Epoch 58/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 136ms/step - accuracy: 0.9725 - loss: 0.0676 - val_accuracy: 0.9684 - val_loss: 0.0923\n",
      "Epoch 59/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - accuracy: 0.9823 - loss: 0.0641 - val_accuracy: 0.9684 - val_loss: 0.0818\n",
      "Epoch 60/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - accuracy: 0.9610 - loss: 0.1085 - val_accuracy: 0.9713 - val_loss: 0.0932\n",
      "Epoch 61/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 135ms/step - accuracy: 0.9688 - loss: 0.0783 - val_accuracy: 0.9856 - val_loss: 0.0664\n",
      "Epoch 62/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 136ms/step - accuracy: 0.9790 - loss: 0.0566 - val_accuracy: 0.9598 - val_loss: 0.1027\n",
      "Epoch 63/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 137ms/step - accuracy: 0.9640 - loss: 0.1144 - val_accuracy: 0.9741 - val_loss: 0.0791\n",
      "Epoch 64/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 135ms/step - accuracy: 0.9789 - loss: 0.0645 - val_accuracy: 0.9655 - val_loss: 0.1174\n",
      "Epoch 65/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - accuracy: 0.9619 - loss: 0.0997 - val_accuracy: 0.9483 - val_loss: 0.1816\n",
      "Epoch 66/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - accuracy: 0.9839 - loss: 0.0521 - val_accuracy: 0.9511 - val_loss: 0.1331\n",
      "Epoch 67/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 141ms/step - accuracy: 0.9725 - loss: 0.0722 - val_accuracy: 0.8678 - val_loss: 0.4592\n",
      "Epoch 68/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 137ms/step - accuracy: 0.9644 - loss: 0.1243 - val_accuracy: 0.9713 - val_loss: 0.0735\n",
      "Epoch 69/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - accuracy: 0.9836 - loss: 0.0466 - val_accuracy: 0.9511 - val_loss: 0.1155\n",
      "Epoch 70/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - accuracy: 0.9755 - loss: 0.0674 - val_accuracy: 0.9770 - val_loss: 0.0702\n",
      "Epoch 71/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step - accuracy: 0.9774 - loss: 0.0496 - val_accuracy: 0.9741 - val_loss: 0.0717\n",
      "Epoch 72/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 137ms/step - accuracy: 0.9801 - loss: 0.0753 - val_accuracy: 0.8994 - val_loss: 0.2769\n",
      "Epoch 73/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 139ms/step - accuracy: 0.9771 - loss: 0.0652 - val_accuracy: 0.9425 - val_loss: 0.1952\n",
      "Epoch 74/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - accuracy: 0.9740 - loss: 0.0906 - val_accuracy: 0.9684 - val_loss: 0.1144\n",
      "Epoch 75/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - accuracy: 0.9737 - loss: 0.0939 - val_accuracy: 0.9483 - val_loss: 0.1655\n",
      "Epoch 76/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step - accuracy: 0.9830 - loss: 0.0603 - val_accuracy: 0.9655 - val_loss: 0.1250\n",
      "Epoch 77/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.9885 - loss: 0.0327 - val_accuracy: 0.9770 - val_loss: 0.1210\n",
      "Epoch 78/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.9888 - loss: 0.0437 - val_accuracy: 0.9540 - val_loss: 0.1351\n",
      "Epoch 79/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - accuracy: 0.9893 - loss: 0.0429 - val_accuracy: 0.9626 - val_loss: 0.0928\n",
      "Epoch 80/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - accuracy: 0.9853 - loss: 0.0409 - val_accuracy: 0.9684 - val_loss: 0.0768\n",
      "Epoch 81/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 127ms/step - accuracy: 0.9864 - loss: 0.0340 - val_accuracy: 0.9828 - val_loss: 0.0776\n",
      "Epoch 82/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - accuracy: 0.9538 - loss: 0.1336 - val_accuracy: 0.9741 - val_loss: 0.1197\n",
      "Epoch 83/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - accuracy: 0.9727 - loss: 0.0778 - val_accuracy: 0.8937 - val_loss: 0.3669\n",
      "Epoch 84/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 136ms/step - accuracy: 0.9754 - loss: 0.1041 - val_accuracy: 0.9856 - val_loss: 0.0932\n",
      "Epoch 85/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - accuracy: 0.9738 - loss: 0.0908 - val_accuracy: 0.9684 - val_loss: 0.1534\n",
      "Epoch 86/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 140ms/step - accuracy: 0.9524 - loss: 0.2056 - val_accuracy: 0.9511 - val_loss: 0.1866\n",
      "Epoch 87/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 137ms/step - accuracy: 0.9604 - loss: 0.1142 - val_accuracy: 0.9540 - val_loss: 0.1668\n",
      "Epoch 88/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - accuracy: 0.9704 - loss: 0.0839 - val_accuracy: 0.9569 - val_loss: 0.1101\n",
      "Epoch 89/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - accuracy: 0.9797 - loss: 0.0604 - val_accuracy: 0.9368 - val_loss: 0.1876\n",
      "Epoch 90/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 139ms/step - accuracy: 0.9705 - loss: 0.1006 - val_accuracy: 0.9397 - val_loss: 0.2792\n",
      "Epoch 91/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - accuracy: 0.9681 - loss: 0.0646 - val_accuracy: 0.9741 - val_loss: 0.1142\n",
      "Epoch 92/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 137ms/step - accuracy: 0.9826 - loss: 0.0543 - val_accuracy: 0.9569 - val_loss: 0.1508\n",
      "Epoch 93/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - accuracy: 0.9773 - loss: 0.0720 - val_accuracy: 0.9540 - val_loss: 0.2105\n",
      "Epoch 94/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 136ms/step - accuracy: 0.9681 - loss: 0.1050 - val_accuracy: 0.9741 - val_loss: 0.1185\n",
      "Epoch 95/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - accuracy: 0.9880 - loss: 0.0585 - val_accuracy: 0.9741 - val_loss: 0.1064\n",
      "Epoch 96/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - accuracy: 0.9887 - loss: 0.0310 - val_accuracy: 0.9511 - val_loss: 0.2259\n",
      "Epoch 97/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 136ms/step - accuracy: 0.9683 - loss: 0.1107 - val_accuracy: 0.8333 - val_loss: 0.6693\n",
      "Epoch 98/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 136ms/step - accuracy: 0.9791 - loss: 0.0540 - val_accuracy: 0.9741 - val_loss: 0.1183\n",
      "Epoch 99/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 130ms/step - accuracy: 0.9885 - loss: 0.0360 - val_accuracy: 0.9598 - val_loss: 0.1979\n",
      "Epoch 100/100\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.9796 - loss: 0.0616 - val_accuracy: 0.9799 - val_loss: 0.0861\n",
      "Model training selesai dan disimpan sebagai efficientnetb7_apple_leaf_disease.h5\n"
     ]
    }
   ],
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Fungsi untuk memuat dan preprocess citra\n",
    "def load_images_and_labels(image_dir, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(image_dir)\n",
    "    class_dict = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(image_dir, class_name)\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Gagal memuat gambar: {image_path}\")\n",
    "                continue\n",
    "            image = cv2.resize(image, image_size)\n",
    "            images.append(image)\n",
    "            labels.append(class_dict[class_name])\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, class_dict\n",
    "\n",
    "# Path dataset\n",
    "base_dir = 'data/split_train_test_dataset_campuran'\n",
    "\n",
    "# Load dataset train, val, test\n",
    "image_size = (224, 224)  # Ukuran citra input yang sesuai untuk EfficientNetB7\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "X_train, y_train, class_dict = load_images_and_labels(train_dir, image_size)\n",
    "X_val, y_val, _ = load_images_and_labels(val_dir, image_size)\n",
    "X_test, y_test, _ = load_images_and_labels(test_dir, image_size)\n",
    "\n",
    "# Normalisasi citra\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Data augmentation untuk training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "# Preprocess input sesuai dengan EfficientNetB7\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=16)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=16)\n",
    "\n",
    "# Load model EfficientNet B7 tanpa pre-trained weights\n",
    "base_model = EfficientNetB0(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Menambahkan layer klasifikasi\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
    "predictions = Dense(len(class_dict), activation='softmax')(x)  # Output layer\n",
    "\n",
    "# Membangun model lengkap\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training model\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=100)\n",
    "\n",
    "# Save model\n",
    "model.save('efficientnetb7_apple_leaf_disease.keras')\n",
    "\n",
    "print(\"Model training selesai dan disimpan sebagai efficientnetb7_apple_leaf_disease.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9ddbf6-abb9-4bfa-a330-921891a35413",
   "metadata": {},
   "source": [
    "# B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82350cf8-f534-4610-ab0b-f4266d5f935b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 1s/step - accuracy: 0.3436 - loss: 1.5774 - val_accuracy: 0.3420 - val_loss: 1.1607\n",
      "Epoch 2/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 158ms/step - accuracy: 0.3352 - loss: 1.8149 - val_accuracy: 0.3592 - val_loss: 1.1112\n",
      "Epoch 3/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 158ms/step - accuracy: 0.3560 - loss: 1.7467 - val_accuracy: 0.3420 - val_loss: 1.1261\n",
      "Epoch 4/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 157ms/step - accuracy: 0.3497 - loss: 1.9724 - val_accuracy: 0.3592 - val_loss: 1.0992\n",
      "Epoch 5/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 160ms/step - accuracy: 0.3802 - loss: 1.6082 - val_accuracy: 0.3592 - val_loss: 1.0980\n",
      "Epoch 6/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 159ms/step - accuracy: 0.3939 - loss: 1.7253 - val_accuracy: 0.3420 - val_loss: 1.0992\n",
      "Epoch 7/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 156ms/step - accuracy: 0.3970 - loss: 1.7758 - val_accuracy: 0.3420 - val_loss: 1.0991\n",
      "Epoch 8/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 159ms/step - accuracy: 0.3496 - loss: 1.8346 - val_accuracy: 0.3276 - val_loss: 8.7315\n",
      "Epoch 9/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 156ms/step - accuracy: 0.3815 - loss: 1.6227 - val_accuracy: 0.3506 - val_loss: 1.1000\n",
      "Epoch 10/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 141ms/step - accuracy: 0.3715 - loss: 1.7777 - val_accuracy: 0.3506 - val_loss: 1.1395\n",
      "Epoch 11/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 154ms/step - accuracy: 0.3693 - loss: 1.6708 - val_accuracy: 0.4023 - val_loss: 3.7831\n",
      "Epoch 12/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 146ms/step - accuracy: 0.3579 - loss: 1.1015 - val_accuracy: 0.3621 - val_loss: 1.0904\n",
      "Epoch 13/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 152ms/step - accuracy: 0.3664 - loss: 1.0928 - val_accuracy: 0.4282 - val_loss: 1.0800\n",
      "Epoch 14/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 156ms/step - accuracy: 0.3704 - loss: 1.0828 - val_accuracy: 0.4483 - val_loss: 1.0611\n",
      "Epoch 15/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 143ms/step - accuracy: 0.3938 - loss: 1.0867 - val_accuracy: 0.4540 - val_loss: 1.0726\n",
      "Epoch 16/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 144ms/step - accuracy: 0.3567 - loss: 1.0872 - val_accuracy: 0.4167 - val_loss: 1.0781\n",
      "Epoch 17/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 149ms/step - accuracy: 0.3901 - loss: 1.0696 - val_accuracy: 0.4167 - val_loss: 1.0639\n",
      "Epoch 18/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 151ms/step - accuracy: 0.3764 - loss: 1.0896 - val_accuracy: 0.4397 - val_loss: 1.0402\n",
      "Epoch 19/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 152ms/step - accuracy: 0.3920 - loss: 1.0767 - val_accuracy: 0.4310 - val_loss: 1.0310\n",
      "Epoch 20/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 147ms/step - accuracy: 0.3918 - loss: 1.0689 - val_accuracy: 0.4368 - val_loss: 1.0180\n",
      "Epoch 21/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - accuracy: 0.3997 - loss: 1.0743 - val_accuracy: 0.4397 - val_loss: 1.0281\n",
      "Epoch 22/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 158ms/step - accuracy: 0.4147 - loss: 1.0684 - val_accuracy: 0.4713 - val_loss: 1.0256\n",
      "Epoch 23/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 160ms/step - accuracy: 0.3985 - loss: 1.0691 - val_accuracy: 0.4397 - val_loss: 1.0443\n",
      "Epoch 24/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 147ms/step - accuracy: 0.4038 - loss: 1.0683 - val_accuracy: 0.4167 - val_loss: 1.0414\n",
      "Epoch 25/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 154ms/step - accuracy: 0.4073 - loss: 1.0756 - val_accuracy: 0.4713 - val_loss: 1.0384\n",
      "Epoch 26/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 151ms/step - accuracy: 0.4200 - loss: 1.0636 - val_accuracy: 0.4885 - val_loss: 1.0320\n",
      "Epoch 27/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 147ms/step - accuracy: 0.4174 - loss: 1.0724 - val_accuracy: 0.4454 - val_loss: 1.0233\n",
      "Epoch 28/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 147ms/step - accuracy: 0.3864 - loss: 1.0728 - val_accuracy: 0.4713 - val_loss: 1.0448\n",
      "Epoch 29/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - accuracy: 0.4211 - loss: 1.0680 - val_accuracy: 0.4425 - val_loss: 1.0293\n",
      "Epoch 30/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 151ms/step - accuracy: 0.4331 - loss: 1.0487 - val_accuracy: 0.4310 - val_loss: 1.1246\n",
      "Epoch 31/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 139ms/step - accuracy: 0.3875 - loss: 1.0764 - val_accuracy: 0.4885 - val_loss: 1.0248\n",
      "Epoch 32/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 145ms/step - accuracy: 0.4040 - loss: 1.0433 - val_accuracy: 0.4770 - val_loss: 1.0438\n",
      "Epoch 33/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - accuracy: 0.4257 - loss: 1.0481 - val_accuracy: 0.4626 - val_loss: 1.0009\n",
      "Epoch 34/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - accuracy: 0.4296 - loss: 1.0491 - val_accuracy: 0.4397 - val_loss: 1.0375\n",
      "Epoch 35/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 147ms/step - accuracy: 0.4369 - loss: 1.0540 - val_accuracy: 0.4741 - val_loss: 0.9932\n",
      "Epoch 36/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 152ms/step - accuracy: 0.4370 - loss: 1.0612 - val_accuracy: 0.4856 - val_loss: 1.0153\n",
      "Epoch 37/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 149ms/step - accuracy: 0.4473 - loss: 1.0383 - val_accuracy: 0.4425 - val_loss: 1.0610\n",
      "Epoch 38/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 158ms/step - accuracy: 0.4363 - loss: 1.0313 - val_accuracy: 0.4598 - val_loss: 1.0382\n",
      "Epoch 39/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 159ms/step - accuracy: 0.4440 - loss: 1.0365 - val_accuracy: 0.4397 - val_loss: 1.0739\n",
      "Epoch 40/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 159ms/step - accuracy: 0.4543 - loss: 1.0258 - val_accuracy: 0.5029 - val_loss: 0.9983\n",
      "Epoch 41/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 160ms/step - accuracy: 0.4379 - loss: 1.0504 - val_accuracy: 0.4626 - val_loss: 1.0923\n",
      "Epoch 42/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 153ms/step - accuracy: 0.4408 - loss: 1.0300 - val_accuracy: 0.4770 - val_loss: 1.0083\n",
      "Epoch 43/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 149ms/step - accuracy: 0.4280 - loss: 1.0428 - val_accuracy: 0.4626 - val_loss: 0.9805\n",
      "Epoch 44/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 145ms/step - accuracy: 0.4915 - loss: 1.0030 - val_accuracy: 0.4914 - val_loss: 0.9856\n",
      "Epoch 45/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 152ms/step - accuracy: 0.4357 - loss: 1.0312 - val_accuracy: 0.4885 - val_loss: 0.9756\n",
      "Epoch 46/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 151ms/step - accuracy: 0.4750 - loss: 1.0186 - val_accuracy: 0.3736 - val_loss: 1.0482\n",
      "Epoch 47/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 145ms/step - accuracy: 0.4625 - loss: 1.0218 - val_accuracy: 0.4971 - val_loss: 1.0080\n",
      "Epoch 48/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 144ms/step - accuracy: 0.4325 - loss: 1.0082 - val_accuracy: 0.4684 - val_loss: 0.9820\n",
      "Epoch 49/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 148ms/step - accuracy: 0.4921 - loss: 1.0071 - val_accuracy: 0.5000 - val_loss: 0.9761\n",
      "Epoch 50/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 148ms/step - accuracy: 0.4712 - loss: 1.0057 - val_accuracy: 0.5201 - val_loss: 0.9978\n",
      "Model training selesai dan disimpan sebagai efficientnetb7_apple_leaf_disease.keras\n"
     ]
    }
   ],
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Fungsi untuk memuat dan preprocess citra\n",
    "def load_images_and_labels(image_dir, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(image_dir)\n",
    "    class_dict = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(image_dir, class_name)\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Gagal memuat gambar: {image_path}\")\n",
    "                continue\n",
    "            image = cv2.resize(image, image_size)\n",
    "            images.append(image)\n",
    "            labels.append(class_dict[class_name])\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, class_dict\n",
    "\n",
    "# Path dataset\n",
    "base_dir = 'data/split_train_test_dataset_campuran'\n",
    "\n",
    "# Load dataset train, val, test\n",
    "image_size = (240, 240)  # Ukuran citra input yang sesuai untuk EfficientNetB7\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "X_train, y_train, class_dict = load_images_and_labels(train_dir, image_size)\n",
    "X_val, y_val, _ = load_images_and_labels(val_dir, image_size)\n",
    "X_test, y_test, _ = load_images_and_labels(test_dir, image_size)\n",
    "\n",
    "# Normalisasi citra\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Data augmentation untuk training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "# Preprocess input sesuai dengan EfficientNetB7\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=16)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=16)\n",
    "\n",
    "# Load model EfficientNet B7 tanpa pre-trained weights\n",
    "base_model = EfficientNetB1(weights=None, include_top=False, input_shape=(240, 240, 3))\n",
    "\n",
    "# Menambahkan layer klasifikasi\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
    "predictions = Dense(len(class_dict), activation='softmax')(x)  # Output layer\n",
    "\n",
    "# Membangun model lengkap\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training model\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=50)\n",
    "\n",
    "# Save model\n",
    "model.save('efficientnetb1_apple_leaf_disease.keras')\n",
    "\n",
    "print(\"Model training selesai dan disimpan sebagai efficientnetb7_apple_leaf_disease.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b4cbac-cd74-476b-99c4-cddbf9574bfc",
   "metadata": {},
   "source": [
    "# B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360612b5-8a23-487e-970b-fc9e2b26dcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m83/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.3736 - loss: 1.6244"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 07:42:55.672381: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'input_add_multiply_reduce_fusion_29', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 1s/step - accuracy: 0.3731 - loss: 1.6317 - val_accuracy: 0.3420 - val_loss: 1.0974\n",
      "Epoch 2/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 156ms/step - accuracy: 0.3667 - loss: 1.8219 - val_accuracy: 0.3420 - val_loss: 1.1160\n",
      "Epoch 3/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 164ms/step - accuracy: 0.3951 - loss: 1.7720 - val_accuracy: 0.3592 - val_loss: 1.1008\n",
      "Epoch 4/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 158ms/step - accuracy: 0.3797 - loss: 1.8434 - val_accuracy: 0.3420 - val_loss: 1.1028\n",
      "Epoch 5/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 159ms/step - accuracy: 0.3616 - loss: 1.8553 - val_accuracy: 0.3420 - val_loss: 1.1488\n",
      "Epoch 6/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 159ms/step - accuracy: 0.4184 - loss: 1.8470 - val_accuracy: 0.3937 - val_loss: 1.0955\n",
      "Epoch 7/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 165ms/step - accuracy: 0.3869 - loss: 1.8574 - val_accuracy: 0.3592 - val_loss: 1.0970\n",
      "Epoch 8/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 167ms/step - accuracy: 0.3789 - loss: 1.8524 - val_accuracy: 0.4368 - val_loss: 1.0921\n",
      "Epoch 9/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 171ms/step - accuracy: 0.3862 - loss: 1.7387 - val_accuracy: 0.3621 - val_loss: 1.0826\n",
      "Epoch 10/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 172ms/step - accuracy: 0.3959 - loss: 1.4547 - val_accuracy: 0.4684 - val_loss: 1.3121\n",
      "Epoch 11/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 175ms/step - accuracy: 0.4370 - loss: 1.3511 - val_accuracy: 0.5029 - val_loss: 1.4088\n",
      "Epoch 12/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 168ms/step - accuracy: 0.4550 - loss: 1.4165 - val_accuracy: 0.4741 - val_loss: 1.4935\n",
      "Epoch 13/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 174ms/step - accuracy: 0.4690 - loss: 1.5373 - val_accuracy: 0.5316 - val_loss: 1.8747\n",
      "Epoch 14/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 176ms/step - accuracy: 0.4415 - loss: 1.6683 - val_accuracy: 0.3218 - val_loss: nan\n",
      "Epoch 15/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 170ms/step - accuracy: 0.3761 - loss: 1.5030 - val_accuracy: 0.2989 - val_loss: 11.3012\n",
      "Epoch 16/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 180ms/step - accuracy: 0.3553 - loss: 1.6952 - val_accuracy: 0.3218 - val_loss: nan\n",
      "Epoch 17/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 176ms/step - accuracy: 0.3720 - loss: 1.5634 - val_accuracy: 0.3879 - val_loss: nan\n",
      "Epoch 18/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 172ms/step - accuracy: 0.3762 - loss: 1.5311 - val_accuracy: 0.4052 - val_loss: 2.3257\n",
      "Epoch 19/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 171ms/step - accuracy: 0.3793 - loss: 1.3973 - val_accuracy: 0.4138 - val_loss: 1.0895\n",
      "Epoch 20/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 173ms/step - accuracy: 0.3984 - loss: 1.4732 - val_accuracy: 0.4224 - val_loss: 1.1348\n",
      "Epoch 21/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 173ms/step - accuracy: 0.4204 - loss: 1.5289 - val_accuracy: 0.3851 - val_loss: 1.2274\n",
      "Epoch 22/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 169ms/step - accuracy: 0.3738 - loss: 1.5892 - val_accuracy: 0.4368 - val_loss: nan\n",
      "Epoch 23/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 169ms/step - accuracy: 0.4178 - loss: 1.5577 - val_accuracy: 0.3477 - val_loss: 1.0759\n",
      "Epoch 24/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 163ms/step - accuracy: 0.3677 - loss: 2.1405 - val_accuracy: 0.2701 - val_loss: 7.9344\n",
      "Epoch 25/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 171ms/step - accuracy: 0.3585 - loss: 1.7358 - val_accuracy: 0.3678 - val_loss: 1.4550\n",
      "Epoch 26/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 180ms/step - accuracy: 0.3387 - loss: 1.7126 - val_accuracy: 0.3362 - val_loss: 1.9422\n",
      "Epoch 27/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 158ms/step - accuracy: 0.3553 - loss: 1.7643 - val_accuracy: 0.3937 - val_loss: 3.2777\n",
      "Epoch 28/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 177ms/step - accuracy: 0.3820 - loss: 1.7209 - val_accuracy: 0.3592 - val_loss: 2.2194\n",
      "Epoch 29/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 159ms/step - accuracy: 0.3605 - loss: 1.5528 - val_accuracy: 0.3592 - val_loss: 2.0220\n",
      "Epoch 30/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 183ms/step - accuracy: 0.3549 - loss: 1.7720 - val_accuracy: 0.3621 - val_loss: 1.8116\n",
      "Epoch 31/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 186ms/step - accuracy: 0.3346 - loss: 1.6541 - val_accuracy: 0.3506 - val_loss: 4.9137\n",
      "Epoch 32/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 175ms/step - accuracy: 0.3504 - loss: 1.6545 - val_accuracy: 0.3161 - val_loss: 2.1697\n",
      "Epoch 33/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 170ms/step - accuracy: 0.3463 - loss: 1.9166 - val_accuracy: 0.3851 - val_loss: 1.2318\n",
      "Epoch 34/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 171ms/step - accuracy: 0.3768 - loss: 1.7450 - val_accuracy: 0.3937 - val_loss: 1.4588\n",
      "Epoch 35/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 172ms/step - accuracy: 0.3525 - loss: 1.5324 - val_accuracy: 0.3908 - val_loss: 1.5112\n",
      "Epoch 36/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 172ms/step - accuracy: 0.3341 - loss: 1.6030 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 37/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 175ms/step - accuracy: 0.3559 - loss: 1.8777 - val_accuracy: 0.3649 - val_loss: 1.1583\n",
      "Epoch 38/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 175ms/step - accuracy: 0.3404 - loss: 1.7322 - val_accuracy: 0.3592 - val_loss: 1.0958\n",
      "Epoch 39/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 177ms/step - accuracy: 0.3553 - loss: 1.7567 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 40/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 171ms/step - accuracy: 0.3629 - loss: 1.8048 - val_accuracy: 0.3592 - val_loss: 1.0956\n",
      "Epoch 41/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 175ms/step - accuracy: 0.3624 - loss: 1.9008 - val_accuracy: 0.3621 - val_loss: 1.0922\n",
      "Epoch 42/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 171ms/step - accuracy: 0.3671 - loss: 1.7869 - val_accuracy: 0.3592 - val_loss: 1.0957\n",
      "Epoch 43/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 176ms/step - accuracy: 0.3519 - loss: 1.8004 - val_accuracy: 0.3592 - val_loss: 1.0961\n",
      "Epoch 44/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 174ms/step - accuracy: 0.3414 - loss: 1.8073 - val_accuracy: 0.3621 - val_loss: 1.1357\n",
      "Epoch 45/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 177ms/step - accuracy: 0.3424 - loss: 1.5793 - val_accuracy: 0.3592 - val_loss: 1.1393\n",
      "Epoch 46/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 173ms/step - accuracy: 0.3451 - loss: 1.7779 - val_accuracy: 0.3046 - val_loss: 5.3653\n",
      "Epoch 47/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 168ms/step - accuracy: 0.3418 - loss: 1.8816 - val_accuracy: 0.2874 - val_loss: 7.5840\n",
      "Epoch 48/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 175ms/step - accuracy: 0.3458 - loss: 1.8391 - val_accuracy: 0.3362 - val_loss: 3.6094\n",
      "Epoch 49/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 174ms/step - accuracy: 0.3493 - loss: 1.7987 - val_accuracy: 0.3534 - val_loss: 2.1043\n",
      "Epoch 50/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 174ms/step - accuracy: 0.3500 - loss: 1.4994 - val_accuracy: 0.3592 - val_loss: 1.0953\n",
      "Model training selesai dan disimpan sebagai efficientnetb7_apple_leaf_disease.keras\n"
     ]
    }
   ],
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Fungsi untuk memuat dan preprocess citra\n",
    "def load_images_and_labels(image_dir, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(image_dir)\n",
    "    class_dict = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(image_dir, class_name)\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Gagal memuat gambar: {image_path}\")\n",
    "                continue\n",
    "            image = cv2.resize(image, image_size)\n",
    "            images.append(image)\n",
    "            labels.append(class_dict[class_name])\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, class_dict\n",
    "\n",
    "# Path dataset\n",
    "base_dir = 'data/split_train_test_dataset_campuran'\n",
    "\n",
    "# Load dataset train, val, test\n",
    "image_size = (260, 260)  # Ukuran citra input yang sesuai untuk EfficientNetB7\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "X_train, y_train, class_dict = load_images_and_labels(train_dir, image_size)\n",
    "X_val, y_val, _ = load_images_and_labels(val_dir, image_size)\n",
    "X_test, y_test, _ = load_images_and_labels(test_dir, image_size)\n",
    "\n",
    "# Normalisasi citra\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Data augmentation untuk training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "# Preprocess input sesuai dengan EfficientNetB7\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=16)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=16)\n",
    "\n",
    "# Load model EfficientNet B7 tanpa pre-trained weights\n",
    "base_model = EfficientNetB2(weights=None, include_top=False, input_shape=(260, 260, 3))\n",
    "\n",
    "# Menambahkan layer klasifikasi\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
    "predictions = Dense(len(class_dict), activation='softmax')(x)  # Output layer\n",
    "\n",
    "# Membangun model lengkap\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training model\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=50)\n",
    "\n",
    "# Save model\n",
    "model.save('efficientnetb2_apple_leaf_disease.keras')\n",
    "\n",
    "print(\"Model training selesai dan disimpan sebagai efficientnetb7_apple_leaf_disease.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96673d82-a25b-4013-98a0-399e36f71429",
   "metadata": {},
   "source": [
    "# B3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ffdd0b4-53af-4bf5-9726-8e9ee359e080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m68/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m4s\u001b[0m 245ms/step - accuracy: 0.3784 - loss: 1.6828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 08:00:47.983553: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'input_add_multiply_reduce_fusion_4', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_multiply_reduce_fusion_28', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_multiply_reduce_fusion_2', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_multiply_reduce_fusion_27', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_multiply_reduce_fusion_26', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 2s/step - accuracy: 0.3767 - loss: 1.7027 - val_accuracy: 0.3420 - val_loss: 1.1209\n",
      "Epoch 2/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 223ms/step - accuracy: 0.4209 - loss: 1.7737 - val_accuracy: 0.2989 - val_loss: 1.1114\n",
      "Epoch 3/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 207ms/step - accuracy: 0.3425 - loss: 1.8783 - val_accuracy: 0.3420 - val_loss: 1.1162\n",
      "Epoch 4/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 218ms/step - accuracy: 0.3537 - loss: 1.9215 - val_accuracy: 0.3592 - val_loss: 1.0983\n",
      "Epoch 5/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 243ms/step - accuracy: 0.3607 - loss: 1.6085 - val_accuracy: 0.3592 - val_loss: 1.0979\n",
      "Epoch 6/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 239ms/step - accuracy: 0.3627 - loss: 1.1075 - val_accuracy: 0.3592 - val_loss: 1.0982\n",
      "Epoch 7/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 235ms/step - accuracy: 0.3596 - loss: 1.1010 - val_accuracy: 0.3592 - val_loss: 1.0965\n",
      "Epoch 8/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 241ms/step - accuracy: 0.3497 - loss: 1.0958 - val_accuracy: 0.3592 - val_loss: 1.0963\n",
      "Epoch 9/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 240ms/step - accuracy: 0.3503 - loss: 1.0969 - val_accuracy: 0.3592 - val_loss: 1.0963\n",
      "Epoch 10/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 240ms/step - accuracy: 0.3515 - loss: 1.0968 - val_accuracy: 0.3592 - val_loss: 1.0963\n",
      "Epoch 11/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 236ms/step - accuracy: 0.3265 - loss: 1.0939 - val_accuracy: 0.3707 - val_loss: 1.0960\n",
      "Epoch 12/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 223ms/step - accuracy: 0.3683 - loss: 1.0938 - val_accuracy: 0.3046 - val_loss: 1.8000\n",
      "Epoch 13/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 223ms/step - accuracy: 0.3734 - loss: 1.0941 - val_accuracy: 0.2989 - val_loss: 1.8126\n",
      "Epoch 14/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 222ms/step - accuracy: 0.3665 - loss: 1.0911 - val_accuracy: 0.3046 - val_loss: 2.0562\n",
      "Epoch 15/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 193ms/step - accuracy: 0.3615 - loss: 1.1002 - val_accuracy: 0.3592 - val_loss: 1.0964\n",
      "Epoch 16/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 204ms/step - accuracy: 0.3453 - loss: 1.1023 - val_accuracy: 0.3017 - val_loss: 1.4841\n",
      "Epoch 17/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 219ms/step - accuracy: 0.3346 - loss: 1.0998 - val_accuracy: 0.3592 - val_loss: 1.1053\n",
      "Epoch 18/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 202ms/step - accuracy: 0.3580 - loss: 1.0928 - val_accuracy: 0.3678 - val_loss: 1.1809\n",
      "Epoch 19/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 192ms/step - accuracy: 0.3606 - loss: 1.0952 - val_accuracy: 0.2500 - val_loss: 1.2288\n",
      "Epoch 20/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 200ms/step - accuracy: 0.3474 - loss: 1.1030 - val_accuracy: 0.3333 - val_loss: 1.1035\n",
      "Epoch 21/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 196ms/step - accuracy: 0.3585 - loss: 1.0920 - val_accuracy: 0.3649 - val_loss: 2.5141\n",
      "Epoch 22/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 193ms/step - accuracy: 0.3643 - loss: 1.0945 - val_accuracy: 0.3592 - val_loss: 1.0934\n",
      "Epoch 23/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 196ms/step - accuracy: 0.3403 - loss: 1.0919 - val_accuracy: 0.3592 - val_loss: 1.2043\n",
      "Epoch 24/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 206ms/step - accuracy: 0.3629 - loss: 1.0920 - val_accuracy: 0.3621 - val_loss: 2.1747\n",
      "Epoch 25/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 238ms/step - accuracy: 0.3686 - loss: 1.0920 - val_accuracy: 0.3046 - val_loss: 1.1347\n",
      "Epoch 26/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 253ms/step - accuracy: 0.3883 - loss: 1.0902 - val_accuracy: 0.3649 - val_loss: 1.1562\n",
      "Epoch 27/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 245ms/step - accuracy: 0.3717 - loss: 1.0946 - val_accuracy: 0.3793 - val_loss: 1.0894\n",
      "Epoch 28/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 240ms/step - accuracy: 0.3831 - loss: 1.0874 - val_accuracy: 0.3822 - val_loss: 1.0856\n",
      "Epoch 29/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 222ms/step - accuracy: 0.3739 - loss: 1.0902 - val_accuracy: 0.4052 - val_loss: 1.0816\n",
      "Epoch 30/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 224ms/step - accuracy: 0.3892 - loss: 1.0831 - val_accuracy: 0.3161 - val_loss: 1.1509\n",
      "Epoch 31/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 205ms/step - accuracy: 0.3946 - loss: 1.0876 - val_accuracy: 0.2989 - val_loss: 1.1312\n",
      "Epoch 32/50\n",
      "\u001b[1m50/87\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 223ms/step - accuracy: 0.3854 - loss: 1.0740"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 77\u001b[0m\n\u001b[1;32m     74\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Training model\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[1;32m     80\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefficientnetb3_apple_leaf_disease.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Fungsi untuk memuat dan preprocess citra\n",
    "def load_images_and_labels(image_dir, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(image_dir)\n",
    "    class_dict = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(image_dir, class_name)\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Gagal memuat gambar: {image_path}\")\n",
    "                continue\n",
    "            image = cv2.resize(image, image_size)\n",
    "            images.append(image)\n",
    "            labels.append(class_dict[class_name])\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, class_dict\n",
    "\n",
    "# Path dataset\n",
    "base_dir = 'data/split_train_test_dataset_campuran'\n",
    "\n",
    "# Load dataset train, val, test\n",
    "image_size = (300, 300)  # Ukuran citra input yang sesuai untuk EfficientNetB7\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "X_train, y_train, class_dict = load_images_and_labels(train_dir, image_size)\n",
    "X_val, y_val, _ = load_images_and_labels(val_dir, image_size)\n",
    "X_test, y_test, _ = load_images_and_labels(test_dir, image_size)\n",
    "\n",
    "# Normalisasi citra\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Data augmentation untuk training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "# Preprocess input sesuai dengan EfficientNetB7\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=16)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=16)\n",
    "\n",
    "# Load model EfficientNet B7 tanpa pre-trained weights\n",
    "base_model = EfficientNetB3(weights=None, include_top=False, input_shape=(300, 300, 3))\n",
    "\n",
    "# Menambahkan layer klasifikasi\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
    "predictions = Dense(len(class_dict), activation='softmax')(x)  # Output layer\n",
    "\n",
    "# Membangun model lengkap\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training model\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=50)\n",
    "\n",
    "# Save model\n",
    "model.save('efficientnetb3_apple_leaf_disease.keras')\n",
    "\n",
    "print(\"Model training selesai dan disimpan sebagai efficientnetb7_apple_leaf_disease.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d262d4bb-94f7-49a6-867a-ce22aba50a76",
   "metadata": {},
   "source": [
    "# B4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233bd583-2acd-4224-baa1-40760a279788",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Fungsi untuk memuat dan preprocess citra\n",
    "def load_images_and_labels(image_dir, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(image_dir)\n",
    "    class_dict = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(image_dir, class_name)\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Gagal memuat gambar: {image_path}\")\n",
    "                continue\n",
    "            image = cv2.resize(image, image_size)\n",
    "            images.append(image)\n",
    "            labels.append(class_dict[class_name])\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, class_dict\n",
    "\n",
    "# Path dataset\n",
    "base_dir = 'data/split_train_test_dataset_campuran'\n",
    "\n",
    "# Load dataset train, val, test\n",
    "image_size = (380, 380)  # Ukuran citra input yang sesuai untuk EfficientNetB7\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "X_train, y_train, class_dict = load_images_and_labels(train_dir, image_size)\n",
    "X_val, y_val, _ = load_images_and_labels(val_dir, image_size)\n",
    "X_test, y_test, _ = load_images_and_labels(test_dir, image_size)\n",
    "\n",
    "# Normalisasi citra\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Data augmentation untuk training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "# Preprocess input sesuai dengan EfficientNetB7\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=16)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=16)\n",
    "\n",
    "# Load model EfficientNet B7 tanpa pre-trained weights\n",
    "base_model = EfficientNetB4(weights=None, include_top=False, input_shape=(380, 380, 3))\n",
    "\n",
    "# Menambahkan layer klasifikasi\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
    "predictions = Dense(len(class_dict), activation='softmax')(x)  # Output layer\n",
    "\n",
    "# Membangun model lengkap\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training model\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=50)\n",
    "\n",
    "# Save model\n",
    "model.save('efficientnetb4_apple_leaf_disease.keras')\n",
    "\n",
    "print(\"Model training selesai dan disimpan sebagai efficientnetb7_apple_leaf_disease.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d8beca-f12a-410d-9681-98e09286e399",
   "metadata": {},
   "source": [
    "# B5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b507ec93-a0c0-4c02-b78a-f4e85b7cbbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Fungsi untuk memuat dan preprocess citra\n",
    "def load_images_and_labels(image_dir, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(image_dir)\n",
    "    class_dict = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(image_dir, class_name)\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Gagal memuat gambar: {image_path}\")\n",
    "                continue\n",
    "            image = cv2.resize(image, image_size)\n",
    "            images.append(image)\n",
    "            labels.append(class_dict[class_name])\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, class_dict\n",
    "\n",
    "# Path dataset\n",
    "base_dir = 'data/split_train_test_dataset_campuran'\n",
    "\n",
    "# Load dataset train, val, test\n",
    "image_size = (456, 456)  # Ukuran citra input yang sesuai untuk EfficientNetB7\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "X_train, y_train, class_dict = load_images_and_labels(train_dir, image_size)\n",
    "X_val, y_val, _ = load_images_and_labels(val_dir, image_size)\n",
    "X_test, y_test, _ = load_images_and_labels(test_dir, image_size)\n",
    "\n",
    "# Normalisasi citra\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Data augmentation untuk training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "# Preprocess input sesuai dengan EfficientNetB7\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=16)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=16)\n",
    "\n",
    "# Load model EfficientNet B7 tanpa pre-trained weights\n",
    "base_model = EfficientNetB5(weights=None, include_top=False, input_shape=(456, 456, 3))\n",
    "\n",
    "# Menambahkan layer klasifikasi\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
    "predictions = Dense(len(class_dict), activation='softmax')(x)  # Output layer\n",
    "\n",
    "# Membangun model lengkap\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training model\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=50)\n",
    "\n",
    "# Save model\n",
    "model.save('efficientnetb5_apple_leaf_disease.keras')\n",
    "\n",
    "print(\"Model training selesai dan disimpan sebagai efficientnetb7_apple_leaf_disease.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbbdb49-3077-44d9-b113-556df942291d",
   "metadata": {},
   "source": [
    "# B6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c645a30-ed99-4430-82fd-e729579fabd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Fungsi untuk memuat dan preprocess citra\n",
    "def load_images_and_labels(image_dir, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(image_dir)\n",
    "    class_dict = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(image_dir, class_name)\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Gagal memuat gambar: {image_path}\")\n",
    "                continue\n",
    "            image = cv2.resize(image, image_size)\n",
    "            images.append(image)\n",
    "            labels.append(class_dict[class_name])\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, class_dict\n",
    "\n",
    "# Path dataset\n",
    "base_dir = 'data/split_train_test_dataset_campuran'\n",
    "\n",
    "# Load dataset train, val, test\n",
    "image_size = (528, 528)  # Ukuran citra input yang sesuai untuk EfficientNetB7\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "X_train, y_train, class_dict = load_images_and_labels(train_dir, image_size)\n",
    "X_val, y_val, _ = load_images_and_labels(val_dir, image_size)\n",
    "X_test, y_test, _ = load_images_and_labels(test_dir, image_size)\n",
    "\n",
    "# Normalisasi citra\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Data augmentation untuk training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "# Preprocess input sesuai dengan EfficientNetB7\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=16)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=16)\n",
    "\n",
    "# Load model EfficientNet B7 tanpa pre-trained weights\n",
    "base_model = EfficientNetB6(weights=None, include_top=False, input_shape=(528, 528, 3))\n",
    "\n",
    "# Menambahkan layer klasifikasi\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
    "predictions = Dense(len(class_dict), activation='softmax')(x)  # Output layer\n",
    "\n",
    "# Membangun model lengkap\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training model\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=50)\n",
    "\n",
    "# Save model\n",
    "model.save('efficientnetb5_apple_leaf_disease.keras')\n",
    "\n",
    "print(\"Model training selesai dan disimpan sebagai efficientnetb7_apple_leaf_disease.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdc4c99-4d91-498d-a276-a0958f259c06",
   "metadata": {},
   "source": [
    "# B7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a69978a-34f3-44f8-87c7-40aa4ee5564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Fungsi untuk memuat dan preprocess citra\n",
    "def load_images_and_labels(image_dir, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(image_dir)\n",
    "    class_dict = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(image_dir, class_name)\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Gagal memuat gambar: {image_path}\")\n",
    "                continue\n",
    "            image = cv2.resize(image, image_size)\n",
    "            images.append(image)\n",
    "            labels.append(class_dict[class_name])\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, class_dict\n",
    "\n",
    "# Path dataset\n",
    "base_dir = 'data/split_train_test_dataset_campuran'\n",
    "\n",
    "# Load dataset train, val, test\n",
    "image_size = (600, 600)  # Ukuran citra input yang sesuai untuk EfficientNetB7\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "X_train, y_train, class_dict = load_images_and_labels(train_dir, image_size)\n",
    "X_val, y_val, _ = load_images_and_labels(val_dir, image_size)\n",
    "X_test, y_test, _ = load_images_and_labels(test_dir, image_size)\n",
    "\n",
    "# Normalisasi citra\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Data augmentation untuk training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "# Preprocess input sesuai dengan EfficientNetB7\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=16)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=16)\n",
    "\n",
    "# Load model EfficientNet B7 tanpa pre-trained weights\n",
    "base_model = EfficientNetB7(weights=None, include_top=False, input_shape=(600, 600, 3))\n",
    "\n",
    "# Menambahkan layer klasifikasi\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
    "predictions = Dense(len(class_dict), activation='softmax')(x)  # Output layer\n",
    "\n",
    "# Membangun model lengkap\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training model\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=50)\n",
    "\n",
    "# Save model\n",
    "model.save('efficientnetb7_apple_leaf_disease.keras')\n",
    "\n",
    "print(\"Model training selesai dan disimpan sebagai efficientnetb7_apple_leaf_disease.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
